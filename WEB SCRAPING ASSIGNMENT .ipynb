{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 .) To write a python program to display all the header tags from ‘en.wikipedia.org/wiki/Main_Page’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Impoting required libraries for Web Scraping\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import html5lib\n",
    "import html.parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting page url\n",
    "#Getting requests\n",
    "\n",
    "url=\"https://en.wikipedia.org/wiki/Main_Page\"\n",
    "r=requests.get(url)\n",
    "\n",
    "soup=BeautifulSoup(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List all the header tags :\n",
      "\n",
      "<h1 class=\"firstHeading\" id=\"firstHeading\">Main Page</h1>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-tfa-h2\"><span id=\"From_today.27s_featured_article\"></span><span class=\"mw-headline\" id=\"From_today's_featured_article\">From today's featured article</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-dyk-h2\"><span class=\"mw-headline\" id=\"Did_you_know_...\">Did you know ...</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-itn-h2\"><span class=\"mw-headline\" id=\"In_the_news\">In the news</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-otd-h2\"><span class=\"mw-headline\" id=\"On_this_day\">On this day</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-tfp-h2\"><span id=\"Today.27s_featured_picture\"></span><span class=\"mw-headline\" id=\"Today's_featured_picture\">Today's featured picture</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-other\"><span class=\"mw-headline\" id=\"Other_areas_of_Wikipedia\">Other areas of Wikipedia</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-sister\"><span id=\"Wikipedia.27s_sister_projects\"></span><span class=\"mw-headline\" id=\"Wikipedia's_sister_projects\">Wikipedia's sister projects</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-lang\"><span class=\"mw-headline\" id=\"Wikipedia_languages\">Wikipedia languages</span></h2>\n",
      "\n",
      "<h2>Navigation menu</h2>\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-personal-label\">\n",
      "<span>Personal tools</span>\n",
      "</h3>\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-namespaces-label\">\n",
      "<span>Namespaces</span>\n",
      "</h3>\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-variants-label\">\n",
      "<span>Variants</span>\n",
      "</h3>\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-views-label\">\n",
      "<span>Views</span>\n",
      "</h3>\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-cactions-label\">\n",
      "<span>More</span>\n",
      "</h3>\n",
      "\n",
      "<h3>\n",
      "<label for=\"searchInput\">Search</label>\n",
      "</h3>\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-navigation-label\">\n",
      "<span>Navigation</span>\n",
      "</h3>\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-interaction-label\">\n",
      "<span>Contribute</span>\n",
      "</h3>\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-tb-label\">\n",
      "<span>Tools</span>\n",
      "</h3>\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-coll-print_export-label\">\n",
      "<span>Print/export</span>\n",
      "</h3>\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-wikibase-otherprojects-label\">\n",
      "<span>In other projects</span>\n",
      "</h3>\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-lang-label\">\n",
      "<span>Languages</span>\n",
      "</h3>\n"
     ]
    }
   ],
   "source": [
    "#Let's extraxt the header tags\n",
    "\n",
    "header = ['h1' , 'h2' , 'h3' , 'h4' , 'h5' , 'h6']\n",
    "titles = soup.find_all(header)\n",
    "\n",
    "print('List all the header tags :', *titles, sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) To Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. Name, IMDB rating, Year of release) and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_url = \"https://www.imdb.com/list/ls091520106/\"\n",
    "page = requests.get(imdb_url)\n",
    "soup = BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">1.</span>\n",
       " <a href=\"/title/tt0111161/\">The Shawshank Redemption</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(1994)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">2.</span>\n",
       " <a href=\"/title/tt0068646/\">The Godfather</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(1972)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">3.</span>\n",
       " <a href=\"/title/tt0071562/\">The Godfather: Part II</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(1974)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">4.</span>\n",
       " <a href=\"/title/tt0468569/\">The Dark Knight</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(2008)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">5.</span>\n",
       " <a href=\"/title/tt0050083/\">12 Angry Men</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(1957)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">6.</span>\n",
       " <a href=\"/title/tt0108052/\">Schindler's List</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(1993)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">7.</span>\n",
       " <a href=\"/title/tt0167260/\">The Lord of the Rings: The Return of the King</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(2003)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">8.</span>\n",
       " <a href=\"/title/tt0110912/\">Pulp Fiction</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(1994)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">9.</span>\n",
       " <a href=\"/title/tt0060196/\">Il buono, il brutto, il cattivo</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(1966)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">10.</span>\n",
       " <a href=\"/title/tt0137523/\">Fight Club</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(1999)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">11.</span>\n",
       " <a href=\"/title/tt7286456/\">Joker</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(2019)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">12.</span>\n",
       " <a href=\"/title/tt0120737/\">The Lord of the Rings: The Fellowship of the Ring</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(2001)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">13.</span>\n",
       " <a href=\"/title/tt0109830/\">Forrest Gump</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(1994)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">14.</span>\n",
       " <a href=\"/title/tt1375666/\">Inception</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(2010)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">15.</span>\n",
       " <a href=\"/title/tt0080684/\">Star Wars: Episode V - The Empire Strikes Back</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(1980)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">16.</span>\n",
       " <a href=\"/title/tt0167261/\">The Lord of the Rings: The Two Towers</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(2002)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">17.</span>\n",
       " <a href=\"/title/tt0133093/\">The Matrix</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(1999)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">18.</span>\n",
       " <a href=\"/title/tt0073486/\">One Flew Over the Cuckoo's Nest</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(1975)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">19.</span>\n",
       " <a href=\"/title/tt0099685/\">Goodfellas</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(1990)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">20.</span>\n",
       " <a href=\"/title/tt0047478/\">Shichinin no samurai</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(1954)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">21.</span>\n",
       " <a href=\"/title/tt0114369/\">Se7en</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(1995)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">22.</span>\n",
       " <a href=\"/title/tt0317248/\">Cidade de Deus</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(2002)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">23.</span>\n",
       " <a href=\"/title/tt0118799/\">La vita è bella</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(1997)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">24.</span>\n",
       " <a href=\"/title/tt0102926/\">The Silence of the Lambs</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(1991)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">25.</span>\n",
       " <a href=\"/title/tt0076759/\">Star Wars</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(1977)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">26.</span>\n",
       " <a href=\"/title/tt0038650/\">It's a Wonderful Life</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(1946)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">27.</span>\n",
       " <a href=\"/title/tt0120815/\">Saving Private Ryan</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(1998)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">28.</span>\n",
       " <a href=\"/title/tt0245429/\">Sen to Chihiro no kamikakushi</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(2001)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">29.</span>\n",
       " <a href=\"/title/tt0120689/\">The Green Mile</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(1999)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">30.</span>\n",
       " <a href=\"/title/tt0110413/\">Léon</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(1994)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">31.</span>\n",
       " <a href=\"/title/tt0056058/\">Seppuku</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(1962)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">32.</span>\n",
       " <a href=\"/title/tt0816692/\">Interstellar</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(2014)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">33.</span>\n",
       " <a href=\"/title/tt0114814/\">The Usual Suspects</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(1995)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">34.</span>\n",
       " <a href=\"/title/tt0110357/\">The Lion King</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(1994)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">35.</span>\n",
       " <a href=\"/title/tt0120586/\">American History X</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(1998)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">36.</span>\n",
       " <a href=\"/title/tt0088763/\">Back to the Future</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(1985)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">37.</span>\n",
       " <a href=\"/title/tt0253474/\">The Pianist</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(2002)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">38.</span>\n",
       " <a href=\"/title/tt0027977/\">Modern Times</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(1936)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">39.</span>\n",
       " <a href=\"/title/tt0103064/\">Terminator 2: Judgment Day</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(1991)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">40.</span>\n",
       " <a href=\"/title/tt1675434/\">The Intouchables</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(2011)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">41.</span>\n",
       " <a href=\"/title/tt0054215/\">Psycho</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(1960)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">42.</span>\n",
       " <a href=\"/title/tt0172495/\">Gladiator</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(2000)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">43.</span>\n",
       " <a href=\"/title/tt0021749/\">City Lights</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(1931)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">44.</span>\n",
       " <a href=\"/title/tt0407887/\">The Departed</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(2006)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">45.</span>\n",
       " <a href=\"/title/tt2582802/\">Whiplash</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(2014)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">46.</span>\n",
       " <a href=\"/title/tt0064116/\">Once Upon a Time in the West</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(1968)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">47.</span>\n",
       " <a href=\"/title/tt0482571/\">The Prestige</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(2006)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">48.</span>\n",
       " <a href=\"/title/tt4154796/\">Avengers: Endgame</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(2019)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">49.</span>\n",
       " <a href=\"/title/tt0034583/\">Casablanca</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(1942)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">50.</span>\n",
       " <a href=\"/title/tt0095327/\">Hotaru no haka</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(1988)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">51.</span>\n",
       " <a href=\"/title/tt0047396/\">Rear Window</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(1954)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">52.</span>\n",
       " <a href=\"/title/tt0095765/\">Nuovo Cinema Paradiso</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(1988)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">53.</span>\n",
       " <a href=\"/title/tt0078748/\">Alien</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(1979)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">54.</span>\n",
       " <a href=\"/title/tt0082971/\">Raiders of the Lost Ark</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(1981)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">55.</span>\n",
       " <a href=\"/title/tt0209144/\">Memento</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(2000)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">56.</span>\n",
       " <a href=\"/title/tt0078788/\">Apocalypse Now</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(1979)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">57.</span>\n",
       " <a href=\"/title/tt0032553/\">The Great Dictator</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(1940)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">58.</span>\n",
       " <a href=\"/title/tt0405094/\">The Lives of Others</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(2006)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">59.</span>\n",
       " <a href=\"/title/tt4154756/\">Avengers: Infinity War</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(2018)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">60.</span>\n",
       " <a href=\"/title/tt1853728/\">Django Unchained</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(2012)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">61.</span>\n",
       " <a href=\"/title/tt4633694/\">Spider-Man: Into the Spider-Verse</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(2018)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">62.</span>\n",
       " <a href=\"/title/tt0081505/\">The Shining</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(1980)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">63.</span>\n",
       " <a href=\"/title/tt0050825/\">Paths of Glory</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(1957)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">64.</span>\n",
       " <a href=\"/title/tt0910970/\">WALL·E</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(2008)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">65.</span>\n",
       " <a href=\"/title/tt0043014/\">Sunset Blvd.</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(1950)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">66.</span>\n",
       " <a href=\"/title/tt0057012/\">Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(1964)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">67.</span>\n",
       " <a href=\"/title/tt0119698/\">Mononoke-hime</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(1997)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">68.</span>\n",
       " <a href=\"/title/tt0364569/\">Oldeuboi</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(2003)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">69.</span>\n",
       " <a href=\"/title/tt0051201/\">Witness for the Prosecution</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(1957)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">70.</span>\n",
       " <a href=\"/title/tt1345836/\">The Dark Knight Rises</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(2012)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">71.</span>\n",
       " <a href=\"/title/tt0087843/\">Once Upon a Time in America</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(1984)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">72.</span>\n",
       " <a href=\"/title/tt6751668/\">Gisaengchung</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(2019)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">73.</span>\n",
       " <a href=\"/title/tt0090605/\">Aliens</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(1986)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">74.</span>\n",
       " <a href=\"/title/tt0169547/\">American Beauty</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(1999)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">75.</span>\n",
       " <a href=\"/title/tt2380307/\">Coco</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(I) (2017)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">76.</span>\n",
       " <a href=\"/title/tt5311514/\">Kimi no na wa.</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(2016)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">77.</span>\n",
       " <a href=\"/title/tt0112573/\">Braveheart</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(1995)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">78.</span>\n",
       " <a href=\"/title/tt0082096/\">Das Boot</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(1981)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">79.</span>\n",
       " <a href=\"/title/tt1187043/\">3 Idiots</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(2009)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">80.</span>\n",
       " <a href=\"/title/tt0986264/\">Taare Zameen Par</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(2007)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">81.</span>\n",
       " <a href=\"/title/tt0086190/\">Star Wars: Episode VI - Return of the Jedi</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(1983)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">82.</span>\n",
       " <a href=\"/title/tt0114709/\">Toy Story</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(1995)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">83.</span>\n",
       " <a href=\"/title/tt0105236/\">Reservoir Dogs</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(1992)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">84.</span>\n",
       " <a href=\"/title/tt0086879/\">Amadeus</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(1984)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">85.</span>\n",
       " <a href=\"/title/tt5074352/\">Dangal</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(2016)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">86.</span>\n",
       " <a href=\"/title/tt0119217/\">Good Will Hunting</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(1997)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">87.</span>\n",
       " <a href=\"/title/tt0361748/\">Inglourious Basterds</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(2009)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">88.</span>\n",
       " <a href=\"/title/tt0022100/\">M - Eine Stadt sucht einen Mörder</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(1931)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">89.</span>\n",
       " <a href=\"/title/tt0180093/\">Requiem for a Dream</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(2000)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">90.</span>\n",
       " <a href=\"/title/tt0062622/\">2001: A Space Odyssey</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(1968)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">91.</span>\n",
       " <a href=\"/title/tt0052357/\">Vertigo</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(1958)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">92.</span>\n",
       " <a href=\"/title/tt0338013/\">Eternal Sunshine of the Spotless Mind</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(2004)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">93.</span>\n",
       " <a href=\"/title/tt0033467/\">Citizen Kane</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(1941)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">94.</span>\n",
       " <a href=\"/title/tt0093058/\">Full Metal Jacket</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(1987)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">95.</span>\n",
       " <a href=\"/title/tt2106476/\">Jagten</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(2012)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">96.</span>\n",
       " <a href=\"/title/tt0053125/\">North by Northwest</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(1959)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">97.</span>\n",
       " <a href=\"/title/tt0066921/\">A Clockwork Orange</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(1971)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">98.</span>\n",
       " <a href=\"/title/tt0208092/\">Snatch</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(2000)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">99.</span>\n",
       " <a href=\"/title/tt0211915/\">Le fabuleux destin d'Amélie Poulain</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(2001)</span>\n",
       " </h3>,\n",
       " <h3 class=\"lister-item-header\">\n",
       " <span class=\"lister-item-index unbold text-primary\">100.</span>\n",
       " <a href=\"/title/tt0012349/\">The Kid</a>\n",
       " <span class=\"lister-item-year text-muted unbold\">(1921)</span>\n",
       " </h3>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting Html Tags where we have movie title\n",
    "\n",
    "movie_title = soup.find_all('h3', class_=\"lister-item-header\")\n",
    "movie_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1.The Shawshank Redemption(1994)',\n",
       " '2.The Godfather(1972)',\n",
       " '3.The Godfather: Part II(1974)',\n",
       " '4.The Dark Knight(2008)',\n",
       " '5.12 Angry Men(1957)',\n",
       " \"6.Schindler's List(1993)\",\n",
       " '7.The Lord of the Rings: The Return of the King(2003)',\n",
       " '8.Pulp Fiction(1994)',\n",
       " '9.Il buono, il brutto, il cattivo(1966)',\n",
       " '10.Fight Club(1999)',\n",
       " '11.Joker(2019)',\n",
       " '12.The Lord of the Rings: The Fellowship of the Ring(2001)',\n",
       " '13.Forrest Gump(1994)',\n",
       " '14.Inception(2010)',\n",
       " '15.Star Wars: Episode V - The Empire Strikes Back(1980)',\n",
       " '16.The Lord of the Rings: The Two Towers(2002)',\n",
       " '17.The Matrix(1999)',\n",
       " \"18.One Flew Over the Cuckoo's Nest(1975)\",\n",
       " '19.Goodfellas(1990)',\n",
       " '20.Shichinin no samurai(1954)',\n",
       " '21.Se7en(1995)',\n",
       " '22.Cidade de Deus(2002)',\n",
       " '23.La vita è bella(1997)',\n",
       " '24.The Silence of the Lambs(1991)',\n",
       " '25.Star Wars(1977)',\n",
       " \"26.It's a Wonderful Life(1946)\",\n",
       " '27.Saving Private Ryan(1998)',\n",
       " '28.Sen to Chihiro no kamikakushi(2001)',\n",
       " '29.The Green Mile(1999)',\n",
       " '30.Léon(1994)',\n",
       " '31.Seppuku(1962)',\n",
       " '32.Interstellar(2014)',\n",
       " '33.The Usual Suspects(1995)',\n",
       " '34.The Lion King(1994)',\n",
       " '35.American History X(1998)',\n",
       " '36.Back to the Future(1985)',\n",
       " '37.The Pianist(2002)',\n",
       " '38.Modern Times(1936)',\n",
       " '39.Terminator 2: Judgment Day(1991)',\n",
       " '40.The Intouchables(2011)',\n",
       " '41.Psycho(1960)',\n",
       " '42.Gladiator(2000)',\n",
       " '43.City Lights(1931)',\n",
       " '44.The Departed(2006)',\n",
       " '45.Whiplash(2014)',\n",
       " '46.Once Upon a Time in the West(1968)',\n",
       " '47.The Prestige(2006)',\n",
       " '48.Avengers: Endgame(2019)',\n",
       " '49.Casablanca(1942)',\n",
       " '50.Hotaru no haka(1988)',\n",
       " '51.Rear Window(1954)',\n",
       " '52.Nuovo Cinema Paradiso(1988)',\n",
       " '53.Alien(1979)',\n",
       " '54.Raiders of the Lost Ark(1981)',\n",
       " '55.Memento(2000)',\n",
       " '56.Apocalypse Now(1979)',\n",
       " '57.The Great Dictator(1940)',\n",
       " '58.The Lives of Others(2006)',\n",
       " '59.Avengers: Infinity War(2018)',\n",
       " '60.Django Unchained(2012)',\n",
       " '61.Spider-Man: Into the Spider-Verse(2018)',\n",
       " '62.The Shining(1980)',\n",
       " '63.Paths of Glory(1957)',\n",
       " '64.WALL·E(2008)',\n",
       " '65.Sunset Blvd.(1950)',\n",
       " '66.Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb(1964)',\n",
       " '67.Mononoke-hime(1997)',\n",
       " '68.Oldeuboi(2003)',\n",
       " '69.Witness for the Prosecution(1957)',\n",
       " '70.The Dark Knight Rises(2012)',\n",
       " '71.Once Upon a Time in America(1984)',\n",
       " '72.Gisaengchung(2019)',\n",
       " '73.Aliens(1986)',\n",
       " '74.American Beauty(1999)',\n",
       " '75.Coco(I) (2017)',\n",
       " '76.Kimi no na wa.(2016)',\n",
       " '77.Braveheart(1995)',\n",
       " '78.Das Boot(1981)',\n",
       " '79.3 Idiots(2009)',\n",
       " '80.Taare Zameen Par(2007)',\n",
       " '81.Star Wars: Episode VI - Return of the Jedi(1983)',\n",
       " '82.Toy Story(1995)',\n",
       " '83.Reservoir Dogs(1992)',\n",
       " '84.Amadeus(1984)',\n",
       " '85.Dangal(2016)',\n",
       " '86.Good Will Hunting(1997)',\n",
       " '87.Inglourious Basterds(2009)',\n",
       " '88.M - Eine Stadt sucht einen Mörder(1931)',\n",
       " '89.Requiem for a Dream(2000)',\n",
       " '90.2001: A Space Odyssey(1968)',\n",
       " '91.Vertigo(1958)',\n",
       " '92.Eternal Sunshine of the Spotless Mind(2004)',\n",
       " '93.Citizen Kane(1941)',\n",
       " '94.Full Metal Jacket(1987)',\n",
       " '95.Jagten(2012)',\n",
       " '96.North by Northwest(1959)',\n",
       " '97.A Clockwork Orange(1971)',\n",
       " '98.Snatch(2000)',\n",
       " \"99.Le fabuleux destin d'Amélie Poulain(2001)\",\n",
       " '100.The Kid(1921)']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating an empty list\n",
    "\n",
    "movie_titles = []\n",
    "\n",
    "#Applying for loop\n",
    "\n",
    "for i in movie_title:\n",
    "    movie_titles.append(i.text.replace(\"\\n\",\"\"))\n",
    "movie_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9.3',\n",
       " '9.2',\n",
       " '9',\n",
       " '9',\n",
       " '9',\n",
       " '8.9',\n",
       " '8.9',\n",
       " '8.9',\n",
       " '8.8',\n",
       " '8.8',\n",
       " '8.4',\n",
       " '8.8',\n",
       " '8.8',\n",
       " '8.8',\n",
       " '8.7',\n",
       " '8.7',\n",
       " '8.7',\n",
       " '8.7',\n",
       " '8.7',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.5',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.4',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.6',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.4',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Similarly for Rating\n",
    "\n",
    "rating = soup.find_all('div' , class_=\"ipl-rating-star small\")\n",
    "\n",
    "movie_rating = []\n",
    "for i in rating:\n",
    "    movie_rating.append(i.text.replace(\"\\n\",\"\"))\n",
    "movie_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100\n"
     ]
    }
   ],
   "source": [
    "print (len(movie_titles) , len(movie_rating)) #Checking length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name and Year</th>\n",
       "      <th>ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.The Shawshank Redemption(1994)</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.The Godfather(1972)</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.The Godfather: Part II(1974)</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.The Dark Knight(2008)</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.12 Angry Men(1957)</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96.North by Northwest(1959)</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97.A Clockwork Orange(1971)</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98.Snatch(2000)</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99.Le fabuleux destin d'Amélie Poulain(2001)</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100.The Kid(1921)</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Name and Year ratings\n",
       "0               1.The Shawshank Redemption(1994)     9.3\n",
       "1                          2.The Godfather(1972)     9.2\n",
       "2                 3.The Godfather: Part II(1974)       9\n",
       "3                        4.The Dark Knight(2008)       9\n",
       "4                           5.12 Angry Men(1957)       9\n",
       "..                                           ...     ...\n",
       "95                   96.North by Northwest(1959)     8.3\n",
       "96                   97.A Clockwork Orange(1971)     8.3\n",
       "97                               98.Snatch(2000)     8.3\n",
       "98  99.Le fabuleux destin d'Amélie Poulain(2001)     8.3\n",
       "99                             100.The Kid(1921)     8.3\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating_Data_Frame\n",
    "\n",
    "import pandas as pd\n",
    "movie = pd.DataFrame({})\n",
    "movie['Name and Year']=movie_titles\n",
    "movie['ratings']=movie_rating\n",
    "movie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.) To write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. Name, IMDB rating, Year of release) and make data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting top 100 Bollywood movies data\n",
    "imdb_url = \"https://www.imdb.com/list/ls009997493/\"\n",
    "page = requests.get(imdb_url)\n",
    "soup = BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1.Rang De Basanti(2006)',\n",
       " '2.3 Idiots(2009)',\n",
       " '3.Taare Zameen Par(2007)',\n",
       " '4.Dil Chahta Hai(2001)',\n",
       " '5.Swades: We, the People(2004)',\n",
       " '6.Lagaan: Once Upon a Time in India(2001)',\n",
       " '7.Gangs of Wasseypur(2012)',\n",
       " '8.Barfi!(2012)',\n",
       " '9.Anand(1971)',\n",
       " '10.Munna Bhai M.B.B.S.(2003)',\n",
       " '11.A Wednesday(2008)',\n",
       " '12.Andaz Apna Apna(1994)',\n",
       " '13.Sholay(1975)',\n",
       " '14.Bhaag Milkha Bhaag(2013)',\n",
       " '15.Hera Pheri(2000)',\n",
       " '16.Udaan(2010)',\n",
       " '17.Kahaani(2012)',\n",
       " '18.Black(2005)',\n",
       " '19.Chak De! India(2007)',\n",
       " '20.Khosla Ka Ghosla!(2006)',\n",
       " '21.Jo Jeeta Wohi Sikandar(1992)',\n",
       " '22.Zindagi Na Milegi Dobara(2011)',\n",
       " '23.Paan Singh Tomar(2012)',\n",
       " '24.Dilwale Dulhania Le Jayenge(1995)',\n",
       " '25.Omkara(2006)',\n",
       " '26.Lage Raho Munna Bhai(2006)',\n",
       " '27.Iqbal(2005)',\n",
       " '28.The Lunchbox(2013)',\n",
       " '29.Black Friday(2004)',\n",
       " '30.Company(2002)',\n",
       " '31.Golmaal(1979)',\n",
       " '32.Dev.D(2009)',\n",
       " '33.Jaane Bhi Do Yaaro(1983)',\n",
       " '34.OMG: Oh My God!(2012)',\n",
       " '35.Mughal-E-Azam(1960)',\n",
       " '36.Gulaal(2009)',\n",
       " '37.Dor(2006)',\n",
       " '38.Jab We Met(2007)',\n",
       " '39.Pyaasa(1957)',\n",
       " '40.The Legend of Bhagat Singh(2002)',\n",
       " '41.Masoom(1983)',\n",
       " '42.Salaam Bombay!(1988)',\n",
       " '43.Satya(1998)',\n",
       " '44.Vicky Donor(2012)',\n",
       " '45.Lakshya(2004)',\n",
       " '46.Vaastav: The Reality(1999)',\n",
       " '47.Kal Ho Naa Ho(2003)',\n",
       " '48.Oye Lucky! Lucky Oye!(2008)',\n",
       " '49.Sarfarosh(1999)',\n",
       " '50.Gangaajal(2003)',\n",
       " '51.Angoor(1982)',\n",
       " '52.Madras Cafe(2013)',\n",
       " '53.English Vinglish(2012)',\n",
       " '54.Chupke Chupke(1975)',\n",
       " '55.Johnny Gaddaar(2007)',\n",
       " '56.Maqbool(2003)',\n",
       " '57.Hazaaron Khwaishein Aisi(2003)',\n",
       " '58.Rock On!!(2008)',\n",
       " '59.Don(1978)',\n",
       " '60.Chhoti Si Baat(1976)',\n",
       " '61.Guide(1965)',\n",
       " '62.Raanjhanaa(2013)',\n",
       " '63.Deewaar(1975)',\n",
       " '64.Special Chabbis(2013)',\n",
       " '65.Padosan(1968)',\n",
       " '66.Mumbai Meri Jaan(2008)',\n",
       " '67.Ab Tak Chhappan(2004)',\n",
       " '68.Kai po che!(2013)',\n",
       " '69.Awaara(1951)',\n",
       " '70.Shree 420(1955)',\n",
       " '71.Earth(1998)',\n",
       " '72.Gunda(1998)',\n",
       " '73.Parinda(1989)',\n",
       " '74.Dasvidaniya(2008)',\n",
       " '75.Hey Ram(2000)',\n",
       " '76.Pinjar: Beyond Boundaries...(2003)',\n",
       " '77.Socha Na Tha(2005)',\n",
       " '78.Guru(2007)',\n",
       " '79.Bawarchi(1972)',\n",
       " '80.Manorama: Six Feet Under(2007)',\n",
       " '81.Mr. India(1987)',\n",
       " '82.Aamir(2008)',\n",
       " '83.Zakhm(1998)',\n",
       " '84.Water(I) (2005)',\n",
       " '85.Stanley Ka Dabba(2011)',\n",
       " '86.Agneepath(1990)',\n",
       " '87.My Name Is Khan(2010)',\n",
       " '88.Qayamat Se Qayamat Tak(1988)',\n",
       " '89.3 Deewarein(2003)',\n",
       " '90.Abhimaan(1973)',\n",
       " '91.Sarkar(2005)',\n",
       " '92.Bheja Fry(2007)',\n",
       " '93.Mother India(1957)',\n",
       " '94.Jaane Tu... Ya Jaane Na(2008)',\n",
       " '95.Delhi Belly(2011)',\n",
       " '96.Wake Up Sid(2009)',\n",
       " '97.Rangeela(1995)',\n",
       " '98.Shatranj Ke Khilari(1977)',\n",
       " '99.Pyaar Ka Punchnama(2011)',\n",
       " '100.Ek Hasina Thi(2004)']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_title = soup.find_all('h3', class_=\"lister-item-header\")\n",
    "\n",
    "#Creating an empty list\n",
    "\n",
    "movie_titles = []\n",
    "for i in movie_title:\n",
    "    movie_titles.append(i.text.replace(\"\\n\",\"\"))\n",
    "movie_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['8.1',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.1',\n",
       " '8.2',\n",
       " '8.1',\n",
       " '8.2',\n",
       " '8.1',\n",
       " '8.3',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.3',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8',\n",
       " '8.1',\n",
       " '7.8',\n",
       " '8.5',\n",
       " '7.9',\n",
       " '8.5',\n",
       " '8',\n",
       " '8.4',\n",
       " '8.1',\n",
       " '8.2',\n",
       " '8.1',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '8.4',\n",
       " '8.1',\n",
       " '8.4',\n",
       " '8',\n",
       " '8.2',\n",
       " '7.8',\n",
       " '7.9',\n",
       " '8',\n",
       " '7.9',\n",
       " '7.7',\n",
       " '8.1',\n",
       " '7.8',\n",
       " '8.3',\n",
       " '7.7',\n",
       " '7.8',\n",
       " '8.3',\n",
       " '7.8',\n",
       " '8.1',\n",
       " '7.9',\n",
       " '7.7',\n",
       " '7.8',\n",
       " '8.3',\n",
       " '8.4',\n",
       " '7.6',\n",
       " '8.1',\n",
       " '8',\n",
       " '8.1',\n",
       " '7.7',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.9',\n",
       " '8',\n",
       " '7.7',\n",
       " '7.3',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.9',\n",
       " '8',\n",
       " '7.4',\n",
       " '7.7',\n",
       " '8',\n",
       " '7.6',\n",
       " '7.8',\n",
       " '7.7',\n",
       " '7.9',\n",
       " '7.7',\n",
       " '7.8',\n",
       " '7.7',\n",
       " '8',\n",
       " '7.5',\n",
       " '7.8',\n",
       " '7.9',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '8',\n",
       " '7.5',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.5',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.5']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating = soup.find_all('div' , class_=\"ipl-rating-star small\")\n",
    "\n",
    "movie_rating = []\n",
    "for i in rating:\n",
    "    movie_rating.append(i.text.replace(\"\\n\",\"\"))\n",
    "movie_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name and Year</th>\n",
       "      <th>ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.Rang De Basanti(2006)</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.3 Idiots(2009)</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.Taare Zameen Par(2007)</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.Dil Chahta Hai(2001)</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.Swades: We, the People(2004)</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96.Wake Up Sid(2009)</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97.Rangeela(1995)</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98.Shatranj Ke Khilari(1977)</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99.Pyaar Ka Punchnama(2011)</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100.Ek Hasina Thi(2004)</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Name and Year ratings\n",
       "0          1.Rang De Basanti(2006)     8.1\n",
       "1                 2.3 Idiots(2009)     8.4\n",
       "2         3.Taare Zameen Par(2007)     8.4\n",
       "3           4.Dil Chahta Hai(2001)     8.1\n",
       "4   5.Swades: We, the People(2004)     8.2\n",
       "..                             ...     ...\n",
       "95            96.Wake Up Sid(2009)     7.6\n",
       "96               97.Rangeela(1995)     7.5\n",
       "97    98.Shatranj Ke Khilari(1977)     7.6\n",
       "98     99.Pyaar Ka Punchnama(2011)     7.6\n",
       "99         100.Ek Hasina Thi(2004)     7.5\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating_Data_Frame\n",
    "\n",
    "import pandas as pd\n",
    "movie = pd.DataFrame({})\n",
    "movie['Name and Year']=movie_titles\n",
    "movie['ratings']=movie_rating\n",
    "movie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.) Write a python program to scrap book name, author name, genre and book review of any 5 books from ‘www.bookpage.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_url = \"https://bookpage.com/reviews?book_genre=fiction&page=1\"\n",
    "page = requests.get(book_url)\n",
    "soup = BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Filthy Animals',\n",
       " 'The Rose Code',\n",
       " ' ★ The Sweetness of Water',\n",
       " 'The Killing Hills',\n",
       " 'Love and Fury',\n",
       " 'The Missing Treasures of Amy Ashton',\n",
       " 'Everyone Knows Your Mother Is a Witch',\n",
       " ' ★ The Hidden Palace',\n",
       " 'One Two Three',\n",
       " ' ★ Walking on Cowrie Shells']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_name = soup.find_all('h4', class_=\"italic\")\n",
    "\n",
    "#Extracting book titles\n",
    "\n",
    "book_titles = []\n",
    "for i in book_name:\n",
    "    book_titles.append(i.text.replace(\"\\n\",\"\"))\n",
    "book_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Brandon Taylor',\n",
       " 'Kate Quinn, Saskia Maarleveld',\n",
       " 'Nathan Harris',\n",
       " 'Chris Offutt',\n",
       " 'Samantha Silva',\n",
       " 'Eleanor Ray',\n",
       " 'Rivka Galchen',\n",
       " 'Helene Wecker',\n",
       " 'Laurie Frankel',\n",
       " 'Nana Nkweti']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting author name\n",
    "\n",
    "author = soup.find_all('p' , class_=\"sans bold\")\n",
    "author_name=[]\n",
    "for i in author:\n",
    "    author_name.append(i.text.replace(\"\\n\",''))\n",
    "author_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fiction / Short Stories',\n",
       " 'Audio / Fiction / Historical Fiction',\n",
       " 'Fiction / Historical Fiction',\n",
       " 'Fiction / Crime Fiction',\n",
       " 'Fiction / Historical Fiction',\n",
       " 'Fiction / Popular Fiction',\n",
       " 'Fiction / Historical Fiction',\n",
       " 'Fiction / Literary Fiction',\n",
       " 'Fiction / Literary Fiction',\n",
       " 'Fiction / Short Stories']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting_Genre\n",
    "\n",
    "genre_=soup.find_all('p',class_='genre-links hidden-phone')\n",
    "genre=[]\n",
    "for i in genre_:\n",
    "    genre.append(i.text.replace(\"\\n\",''))\n",
    "genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['In Brandon Taylor’s short story collection, sexual tension acts like an undertow, lurking to pull its victims down below.', 'The Rose Code is a terrific story, brilliantly performed by Saskia Maarleveld. Or as Osla would say, it’s a real corker!', 'Nathan Harris’ Civil War-set debut novel celebrates all manner of relationships that combat hate.', 'A rural noir with attitude to spare, The Killing Hills moves as briskly as a well-constructed miniseries.', 'Samantha Silva’s attention to period detail creates a worthy elegy to one of the world’s most influential feminist thinkers, Mary Wollstonecraft.', 'Eleanor Ray’s debut novel about a hoarder pokes gentle fun at the absurdities and tragedies of life with quintessential British humor.', 'Rivka Galchen brings a surprising sense of humor to the grim topic of 17th-century witchcraft accusations.', 'Fans have waited eight years for this sequel, a minor eternity perfectly in keeping with the precarious immortality of Helene Wecker’s hopeful monsters.', 'It’s rare when a book is decidedly grim—dire, even—yet still manages to be as full of comfort, humor and hope as One Two Three.', 'With the ease of a master, Nana Nkweti shifts between points of view, between American and African slang, and between the straightforward and the avant-garde.']\n"
     ]
    }
   ],
   "source": [
    "#Similarly Extracting reviews \n",
    "\n",
    "review = soup.find_all('p' , class_='excerpt')\n",
    "reviews=[]\n",
    "for i in review:\n",
    "    reviews.append(i.text.replace(\"\\n\",\"\"))\n",
    "print(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_name</th>\n",
       "      <th>author</th>\n",
       "      <th>genre</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Filthy Animals</td>\n",
       "      <td>Brandon Taylor</td>\n",
       "      <td>Fiction / Short Stories</td>\n",
       "      <td>In Brandon Taylor’s short story collection, se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Rose Code</td>\n",
       "      <td>Kate Quinn, Saskia Maarleveld</td>\n",
       "      <td>Audio / Fiction / Historical Fiction</td>\n",
       "      <td>The Rose Code is a terrific story, brilliantly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>★ The Sweetness of Water</td>\n",
       "      <td>Nathan Harris</td>\n",
       "      <td>Fiction / Historical Fiction</td>\n",
       "      <td>Nathan Harris’ Civil War-set debut novel celeb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Killing Hills</td>\n",
       "      <td>Chris Offutt</td>\n",
       "      <td>Fiction / Crime Fiction</td>\n",
       "      <td>A rural noir with attitude to spare, The Killi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Love and Fury</td>\n",
       "      <td>Samantha Silva</td>\n",
       "      <td>Fiction / Historical Fiction</td>\n",
       "      <td>Samantha Silva’s attention to period detail cr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   book_name                         author  \\\n",
       "0             Filthy Animals                 Brandon Taylor   \n",
       "1              The Rose Code  Kate Quinn, Saskia Maarleveld   \n",
       "2   ★ The Sweetness of Water                  Nathan Harris   \n",
       "3          The Killing Hills                   Chris Offutt   \n",
       "4              Love and Fury                 Samantha Silva   \n",
       "\n",
       "                                  genre  \\\n",
       "0               Fiction / Short Stories   \n",
       "1  Audio / Fiction / Historical Fiction   \n",
       "2          Fiction / Historical Fiction   \n",
       "3               Fiction / Crime Fiction   \n",
       "4          Fiction / Historical Fiction   \n",
       "\n",
       "                                              review  \n",
       "0  In Brandon Taylor’s short story collection, se...  \n",
       "1  The Rose Code is a terrific story, brilliantly...  \n",
       "2  Nathan Harris’ Civil War-set debut novel celeb...  \n",
       "3  A rural noir with attitude to spare, The Killi...  \n",
       "4  Samantha Silva’s attention to period detail cr...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating DataFrame\n",
    "\n",
    "book = pd.DataFrame({})\n",
    "book['book_name']=book_titles\n",
    "book['author']=author_name\n",
    "book['genre']=genre\n",
    "book['review']=reviews\n",
    "\n",
    "#Picking only 5 books as per assignment question\n",
    "\n",
    "books = book.drop(index=[5,6,7,8,9] , axis=0)\n",
    "books"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.) Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’\n",
    "\n",
    "# i.) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "icc_men = \"https://www.icc-cricket.com/rankings/mens/team-rankings/odi\"\n",
    "r = requests.get(icc_men)\n",
    "soup = BeautifulSoup(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<td class=\"rankings-block__banner--pos\">1</td>,\n",
       " <td class=\"table-body__cell table-body__cell--position u-text-right\">2</td>,\n",
       " <td class=\"table-body__cell table-body__cell--position u-text-right\">3</td>,\n",
       " <td class=\"table-body__cell table-body__cell--position u-text-right\">4</td>,\n",
       " <td class=\"table-body__cell table-body__cell--position u-text-right\">5</td>,\n",
       " <td class=\"table-body__cell table-body__cell--position u-text-right\">6</td>,\n",
       " <td class=\"table-body__cell table-body__cell--position u-text-right\">7</td>,\n",
       " <td class=\"table-body__cell table-body__cell--position u-text-right\">8</td>,\n",
       " <td class=\"table-body__cell table-body__cell--position u-text-right\">9</td>,\n",
       " <td class=\"table-body__cell table-body__cell--position u-text-right\">10</td>,\n",
       " <td class=\"table-body__cell table-body__cell--position u-text-right\">11</td>,\n",
       " <td class=\"table-body__cell table-body__cell--position u-text-right\">12</td>,\n",
       " <td class=\"table-body__cell table-body__cell--position u-text-right\">13</td>,\n",
       " <td class=\"table-body__cell table-body__cell--position u-text-right\">14</td>,\n",
       " <td class=\"table-body__cell table-body__cell--position u-text-right\">15</td>,\n",
       " <td class=\"table-body__cell table-body__cell--position u-text-right\">16</td>,\n",
       " <td class=\"table-body__cell table-body__cell--position u-text-right\">17</td>,\n",
       " <td class=\"table-body__cell table-body__cell--position u-text-right\">18</td>,\n",
       " <td class=\"table-body__cell table-body__cell--position u-text-right\">19</td>,\n",
       " <td class=\"table-body__cell table-body__cell--position u-text-right\">20</td>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank1 = soup.find_all('td' , class_= 'rankings-block__banner--pos')\n",
    "rank2 = soup.find_all('td' , class_= 'table-body__cell table-body__cell--position u-text-right')\n",
    "rank = rank1 + rank2 #Combining both as Rank 1 and rest player are from different classes\n",
    "rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " '10',\n",
       " '11',\n",
       " '12',\n",
       " '13',\n",
       " '14',\n",
       " '15',\n",
       " '16',\n",
       " '17',\n",
       " '18',\n",
       " '19',\n",
       " '20']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting Ranking\n",
    "\n",
    "ranking = []\n",
    "for i in rank:\n",
    "    ranking.append(i.text.replace(\"\\n\" , \"\"))\n",
    "ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<td class=\"rankings-block__banner--team-name\">\n",
       " <span class=\"flag-30 rankings-block__banner--flag NZ\"></span>\n",
       " <span class=\"u-hide-phablet\">New Zealand</span>\n",
       " <span class=\"u-show-phablet\">NZ</span>\n",
       " </td>,\n",
       " <td class=\"table-body__cell rankings-table__team\">\n",
       " <span class=\"flag-15 table-body_logo AUS\"></span>\n",
       " <span class=\"u-hide-phablet\">Australia</span>\n",
       " <span class=\"u-show-phablet\">AUS</span>\n",
       " </td>,\n",
       " <td class=\"table-body__cell rankings-table__team\">\n",
       " <span class=\"flag-15 table-body_logo IND\"></span>\n",
       " <span class=\"u-hide-phablet\">India</span>\n",
       " <span class=\"u-show-phablet\">IND</span>\n",
       " </td>,\n",
       " <td class=\"table-body__cell rankings-table__team\">\n",
       " <span class=\"flag-15 table-body_logo ENG\"></span>\n",
       " <span class=\"u-hide-phablet\">England</span>\n",
       " <span class=\"u-show-phablet\">ENG</span>\n",
       " </td>,\n",
       " <td class=\"table-body__cell rankings-table__team\">\n",
       " <span class=\"flag-15 table-body_logo SA\"></span>\n",
       " <span class=\"u-hide-phablet\">South Africa</span>\n",
       " <span class=\"u-show-phablet\">SA</span>\n",
       " </td>,\n",
       " <td class=\"table-body__cell rankings-table__team\">\n",
       " <span class=\"flag-15 table-body_logo PAK\"></span>\n",
       " <span class=\"u-hide-phablet\">Pakistan</span>\n",
       " <span class=\"u-show-phablet\">PAK</span>\n",
       " </td>,\n",
       " <td class=\"table-body__cell rankings-table__team\">\n",
       " <span class=\"flag-15 table-body_logo BAN\"></span>\n",
       " <span class=\"u-hide-phablet\">Bangladesh</span>\n",
       " <span class=\"u-show-phablet\">BAN</span>\n",
       " </td>,\n",
       " <td class=\"table-body__cell rankings-table__team\">\n",
       " <span class=\"flag-15 table-body_logo WI\"></span>\n",
       " <span class=\"u-hide-phablet\">West Indies</span>\n",
       " <span class=\"u-show-phablet\">WI</span>\n",
       " </td>,\n",
       " <td class=\"table-body__cell rankings-table__team\">\n",
       " <span class=\"flag-15 table-body_logo SL\"></span>\n",
       " <span class=\"u-hide-phablet\">Sri Lanka</span>\n",
       " <span class=\"u-show-phablet\">SL</span>\n",
       " </td>,\n",
       " <td class=\"table-body__cell rankings-table__team\">\n",
       " <span class=\"flag-15 table-body_logo AFG\"></span>\n",
       " <span class=\"u-hide-phablet\">Afghanistan</span>\n",
       " <span class=\"u-show-phablet\">AFG</span>\n",
       " </td>,\n",
       " <td class=\"table-body__cell rankings-table__team\">\n",
       " <span class=\"flag-15 table-body_logo NED\"></span>\n",
       " <span class=\"u-hide-phablet\">Netherlands</span>\n",
       " <span class=\"u-show-phablet\">NED</span>\n",
       " </td>,\n",
       " <td class=\"table-body__cell rankings-table__team\">\n",
       " <span class=\"flag-15 table-body_logo IRE\"></span>\n",
       " <span class=\"u-hide-phablet\">Ireland</span>\n",
       " <span class=\"u-show-phablet\">IRE</span>\n",
       " </td>,\n",
       " <td class=\"table-body__cell rankings-table__team\">\n",
       " <span class=\"flag-15 table-body_logo ZIM\"></span>\n",
       " <span class=\"u-hide-phablet\">Zimbabwe</span>\n",
       " <span class=\"u-show-phablet\">ZIM</span>\n",
       " </td>,\n",
       " <td class=\"table-body__cell rankings-table__team\">\n",
       " <span class=\"flag-15 table-body_logo SCO\"></span>\n",
       " <span class=\"u-hide-phablet\">Scotland</span>\n",
       " <span class=\"u-show-phablet\">SCO</span>\n",
       " </td>,\n",
       " <td class=\"table-body__cell rankings-table__team\">\n",
       " <span class=\"flag-15 table-body_logo OMA\"></span>\n",
       " <span class=\"u-hide-phablet\">Oman</span>\n",
       " <span class=\"u-show-phablet\">OMA</span>\n",
       " </td>,\n",
       " <td class=\"table-body__cell rankings-table__team\">\n",
       " <span class=\"flag-15 table-body_logo NEP\"></span>\n",
       " <span class=\"u-hide-phablet\">Nepal</span>\n",
       " <span class=\"u-show-phablet\">NEP</span>\n",
       " </td>,\n",
       " <td class=\"table-body__cell rankings-table__team\">\n",
       " <span class=\"flag-15 table-body_logo UAE\"></span>\n",
       " <span class=\"u-hide-phablet\">UAE</span>\n",
       " <span class=\"u-show-phablet\">UAE</span>\n",
       " </td>,\n",
       " <td class=\"table-body__cell rankings-table__team\">\n",
       " <span class=\"flag-15 table-body_logo NAM\"></span>\n",
       " <span class=\"u-hide-phablet\">Namibia</span>\n",
       " <span class=\"u-show-phablet\">NAM</span>\n",
       " </td>,\n",
       " <td class=\"table-body__cell rankings-table__team\">\n",
       " <span class=\"flag-15 table-body_logo USA\"></span>\n",
       " <span class=\"u-hide-phablet\">United States</span>\n",
       " <span class=\"u-show-phablet\">USA</span>\n",
       " </td>,\n",
       " <td class=\"table-body__cell rankings-table__team\">\n",
       " <span class=\"flag-15 table-body_logo PNG\"></span>\n",
       " <span class=\"u-hide-phablet\">Papua New Guinea</span>\n",
       " <span class=\"u-show-phablet\">PNG</span>\n",
       " </td>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Similarly for teams\n",
    "\n",
    "team1 = soup.find_all('td' , class_= \"rankings-block__banner--team-name\")\n",
    "\n",
    "team2 = soup.find_all('td' , class_= \"table-body__cell rankings-table__team\")\n",
    "\n",
    "teams = team1 + team2\n",
    "teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['  New Zealand NZ ',\n",
       " '  Australia AUS ',\n",
       " '  India IND ',\n",
       " '  England ENG ',\n",
       " '  South Africa SA ',\n",
       " '  Pakistan PAK ',\n",
       " '  Bangladesh BAN ',\n",
       " '  West Indies WI ',\n",
       " '  Sri Lanka SL ',\n",
       " '  Afghanistan AFG ',\n",
       " '  Netherlands NED ',\n",
       " '  Ireland IRE ',\n",
       " '  Zimbabwe ZIM ',\n",
       " '  Scotland SCO ',\n",
       " '  Oman OMA ',\n",
       " '  Nepal NEP ',\n",
       " '  UAE UAE ',\n",
       " '  Namibia NAM ',\n",
       " '  United States USA ',\n",
       " '  Papua New Guinea PNG ']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating an empty list\n",
    "\n",
    "country = []\n",
    "for i in teams:\n",
    "    country.append(i.text.replace(\"\\n\",\" \"))\n",
    "country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['17',\n",
       " '25',\n",
       " '2,945',\n",
       " '29',\n",
       " '3,344',\n",
       " '27',\n",
       " '3,100',\n",
       " '20',\n",
       " '2,137',\n",
       " '24',\n",
       " '2,323',\n",
       " '27',\n",
       " '2,438',\n",
       " '27',\n",
       " '2,222',\n",
       " '24',\n",
       " '1,876',\n",
       " '17',\n",
       " '1,054',\n",
       " '7',\n",
       " '336',\n",
       " '21',\n",
       " '897',\n",
       " '15',\n",
       " '588',\n",
       " '7',\n",
       " '258',\n",
       " '7',\n",
       " '240',\n",
       " '5',\n",
       " '119',\n",
       " '9',\n",
       " '190',\n",
       " '6',\n",
       " '97',\n",
       " '8',\n",
       " '93',\n",
       " '5',\n",
       " '0']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Similarly doing for 'Matches','Points' and 'Rating'\n",
    "matches1 = soup.find_all('td' , class_='rankings-block__banner--matches')\n",
    "matches2 = soup.find_all('td' , class_='table-body__cell u-center-text')\n",
    "match = matches1 + matches2\n",
    "matches = []\n",
    "for i in match:\n",
    "    matches.append(i.text.replace(\"\\n\",\"  \"))\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['17',\n",
       " '25',\n",
       " '29',\n",
       " '27',\n",
       " '20',\n",
       " '24',\n",
       " '27',\n",
       " '27',\n",
       " '24',\n",
       " '17',\n",
       " '7',\n",
       " '21',\n",
       " '15',\n",
       " '7',\n",
       " '7',\n",
       " '5',\n",
       " '9',\n",
       " '6',\n",
       " '8',\n",
       " '5',\n",
       " '0']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del matches[2:38:2]\n",
    "\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['17',\n",
       " '25',\n",
       " '29',\n",
       " '27',\n",
       " '20',\n",
       " '24',\n",
       " '27',\n",
       " '27',\n",
       " '24',\n",
       " '17',\n",
       " '7',\n",
       " '21',\n",
       " '15',\n",
       " '7',\n",
       " '7',\n",
       " '5',\n",
       " '9',\n",
       " '6',\n",
       " '8',\n",
       " '5']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del matches[-1]\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2,054',\n",
       " '25',\n",
       " '2,945',\n",
       " '29',\n",
       " '3,344',\n",
       " '27',\n",
       " '3,100',\n",
       " '20',\n",
       " '2,137',\n",
       " '24',\n",
       " '2,323',\n",
       " '27',\n",
       " '2,438',\n",
       " '27',\n",
       " '2,222',\n",
       " '24',\n",
       " '1,876',\n",
       " '17',\n",
       " '1,054',\n",
       " '7',\n",
       " '336',\n",
       " '21',\n",
       " '897',\n",
       " '15',\n",
       " '588',\n",
       " '7',\n",
       " '258',\n",
       " '7',\n",
       " '240',\n",
       " '5',\n",
       " '119',\n",
       " '9',\n",
       " '190',\n",
       " '6',\n",
       " '97',\n",
       " '8',\n",
       " '93',\n",
       " '5',\n",
       " '0']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points1 = soup.find_all('td' , class_='rankings-block__banner--points')\n",
    "points2 = soup.find_all('td' , class_='table-body__cell u-center-text')\n",
    "point = points1 + points2\n",
    "points = []\n",
    "for i in point:\n",
    "    points.append(i.text.replace(\"\\n\",\"  \"))\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2,054',\n",
       " '2,945',\n",
       " '3,344',\n",
       " '3,100',\n",
       " '2,137',\n",
       " '2,323',\n",
       " '2,438',\n",
       " '2,222',\n",
       " '1,876',\n",
       " '1,054',\n",
       " '336',\n",
       " '897',\n",
       " '588',\n",
       " '258',\n",
       " '240',\n",
       " '119',\n",
       " '190',\n",
       " '97',\n",
       " '93',\n",
       " '0']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del points[1:38:2]\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['                              121                                  ',\n",
       " '118',\n",
       " '115',\n",
       " '115',\n",
       " '107',\n",
       " '97',\n",
       " '90',\n",
       " '82',\n",
       " '78',\n",
       " '62',\n",
       " '48',\n",
       " '43',\n",
       " '39',\n",
       " '37',\n",
       " '34',\n",
       " '24',\n",
       " '21',\n",
       " '16',\n",
       " '12',\n",
       " '0']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ratings\n",
    "rating1 = soup.find_all('td' , class_=\"rankings-block__banner--rating u-text-right\")\n",
    "rating2 = soup.find_all('td' , class_=\"table-body__cell u-text-right rating\")\n",
    "ratings = rating1 + rating2\n",
    "rating = []\n",
    "for i in ratings:\n",
    "    rating.append(i.text.replace(\"\\n\",\"  \"))\n",
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "20\n",
      "20\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "print(len(country))\n",
    "print(len(rating))\n",
    "print(len(matches))\n",
    "print(len(points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ranking</th>\n",
       "      <th>Country</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>New Zealand NZ</td>\n",
       "      <td>17</td>\n",
       "      <td>2,054</td>\n",
       "      <td>121             ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Australia AUS</td>\n",
       "      <td>25</td>\n",
       "      <td>2,945</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>India IND</td>\n",
       "      <td>29</td>\n",
       "      <td>3,344</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>England ENG</td>\n",
       "      <td>27</td>\n",
       "      <td>3,100</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>South Africa SA</td>\n",
       "      <td>20</td>\n",
       "      <td>2,137</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Pakistan PAK</td>\n",
       "      <td>24</td>\n",
       "      <td>2,323</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Bangladesh BAN</td>\n",
       "      <td>27</td>\n",
       "      <td>2,438</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>West Indies WI</td>\n",
       "      <td>27</td>\n",
       "      <td>2,222</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Sri Lanka SL</td>\n",
       "      <td>24</td>\n",
       "      <td>1,876</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Afghanistan AFG</td>\n",
       "      <td>17</td>\n",
       "      <td>1,054</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ranking             Country Matches Points  \\\n",
       "0       1     New Zealand NZ       17  2,054   \n",
       "1       2      Australia AUS       25  2,945   \n",
       "2       3          India IND       29  3,344   \n",
       "3       4        England ENG       27  3,100   \n",
       "4       5    South Africa SA       20  2,137   \n",
       "5       6       Pakistan PAK       24  2,323   \n",
       "6       7     Bangladesh BAN       27  2,438   \n",
       "7       8     West Indies WI       27  2,222   \n",
       "8       9       Sri Lanka SL       24  1,876   \n",
       "9      10    Afghanistan AFG       17  1,054   \n",
       "\n",
       "                                             Ratings  \n",
       "0                                121             ...  \n",
       "1                                                118  \n",
       "2                                                115  \n",
       "3                                                115  \n",
       "4                                                107  \n",
       "5                                                 97  \n",
       "6                                                 90  \n",
       "7                                                 82  \n",
       "8                                                 78  \n",
       "9                                                 62  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({})\n",
    "df['Ranking'] = ranking\n",
    "df['Country'] = country\n",
    "df['Matches'] = matches\n",
    "df['Points'] = points\n",
    "df['Ratings'] = rating\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ii.) Top 10 ODI Batsmen in men along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting\"\n",
    "r = requests.get(url, 'html.parser')\n",
    "soup = BeautifulSoup(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Babar Azam', ' Virat Kohli ', ' Rohit Sharma ', ' Ross Taylor ', ' Aaron Finch ', ' Jonny Bairstow ', ' Fakhar Zaman ', ' Francois du Plessis ', ' David Warner ', ' Shai Hope ', ' Quinton de Kock ', ' Kane Williamson ', ' Imam-ul-Haq ', ' Mushfiqur Rahim ', ' Joe Root ', ' Steve Smith ', ' Martin Guptill ', ' Shikhar Dhawan ', ' Jason Roy ', ' Paul Stirling ', ' Glenn Maxwell ', ' Rassie van der Dussen ', ' Usman Khawaja ', ' Ben Stokes ', ' Tamim Iqbal ', ' Eoin Morgan ', ' Lokesh Rahul ', ' Alex Carey ', ' David Miller ', ' Shimron Hetmyer ', ' Shakib Al Hasan ', ' Jos Buttler ', ' Tom Latham ', ' Nicholas Pooran ', ' Haris Sohail ', ' Mahmudullah ', ' Henry Nicholls ', ' Aqib Ilyas ', ' Kyle Coetzer ', ' Brendan Taylor ', ' Angelo Mathews ', ' Kusal Perera ', ' Hardik Pandya ', ' Sean Williams ', ' Kedar Jadhav ', ' Evin Lewis ', ' Rahmat Shah ', ' Danushka Gunathilaka ', ' Mohammad Hafeez ', ' Kusal Mendis ', ' Andrew Balbirnie ', ' Sikandar Raza ', ' Litton Das ', ' Imad Wasim ', ' Soumya Sarkar ', ' Marcus Stoinis ', ' Mohammad Shahzad ', ' Niroshan Dickwella ', ' Sarfaraz Ahmed ', ' Calum MacLeod ', ' Colin de Grandhomme ', ' Najibullah Zadran ', ' Marnus Labuschagne ', ' Chris Gayle ', ' Hashmatullah Shaidi ', ' Avishka Fernando ', ' Jimmy Neesham ', ' Shaun Marsh ', ' Mohammad Nabi ', ' Mitchell Marsh ', \" Kevin O'Brien \", ' Peter Handscomb ', ' Shreyas Iyer ', ' Asghar Afghan ', ' Richard Berrington ', ' Muhammad Usman ', ' Colin Munro ', ' Craig Ervine ', ' Mitchell Santner ', ' William Porterfield ', ' Heinrich Klaasen ', ' Aiden Markram ', ' Andile Phehlukwayo ', ' Lahiru Thirimanne ', ' Dhananjaya de Silva ', ' Jason Holder ', ' Temba Bavuma ', ' Assad Vala ', ' Ravindra Jadeja ', ' Sabbir Rahman ', ' Mithun Ali ', ' Rishabh Pant ', ' Rashid Khan ', ' George Munsey ', ' Dinesh Chandimal ', ' Rovman Powell ', ' Tony Ura ', ' Gulbadin Naib ', ' Chris Woakes ', ' Sam Billings ']\n"
     ]
    }
   ],
   "source": [
    "#Fetching Player_Name\n",
    "\n",
    "name1 = soup.find_all('div' , class_=\"rankings-block__banner--name-large\")\n",
    "name2 = soup.find_all('td' , class_=\"table-body__cell rankings-table__name name\")\n",
    "name = name1+name2\n",
    "\n",
    "player_name = []\n",
    "for i in name:\n",
    "    player_name.append(i.text.replace(\"\\n\" , \" \"))\n",
    "print(player_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Team\n",
    "\n",
    "team1 = soup.find_all('div' , class_=\"rankings-block__banner--nationality\")\n",
    "team2 = soup.find_all('span' , class_=\"table-body__logo-text\")\n",
    "team = team1+team2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['  PAK                     ', 'IND', 'IND', 'NZ', 'AUS', 'ENG', 'PAK', 'SA', 'AUS', 'WI', 'SA', 'NZ', 'PAK', 'BAN', 'ENG', 'AUS', 'NZ', 'IND', 'ENG', 'IRE', 'AUS', 'SA', 'AUS', 'ENG', 'BAN', 'ENG', 'IND', 'AUS', 'SA', 'WI', 'BAN', 'ENG', 'NZ', 'WI', 'PAK', 'BAN', 'NZ', 'OMA', 'SCO', 'ZIM', 'SL', 'SL', 'IND', 'ZIM', 'IND', 'WI', 'AFG', 'SL', 'PAK', 'SL', 'IRE', 'ZIM', 'BAN', 'PAK', 'BAN', 'AUS', 'AFG', 'SL', 'PAK', 'SCO', 'NZ', 'AFG', 'AUS', 'WI', 'AFG', 'SL', 'NZ', 'AUS', 'AFG', 'AUS', 'IRE', 'AUS', 'IND', 'AFG', 'SCO', 'UAE', 'NZ', 'ZIM', 'NZ', 'IRE', 'SA', 'SA', 'SA', 'SL', 'SL', 'WI', 'SA', 'PNG', 'IND', 'BAN', 'BAN', 'IND', 'AFG', 'SCO', 'SL', 'WI', 'PNG', 'AFG', 'ENG', 'ENG']\n"
     ]
    }
   ],
   "source": [
    "team_name = []\n",
    "for i in team:\n",
    "    team_name.append(i.text.replace(\"\\n\" , \" \"))\n",
    "print(team_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['865', '857', '825', '801', '791', '785', '778', '778', '773', '773', '756', '754', '751', '734', '723', '707', '707', '706', '689', '687', '684', '680', '675', '668', '667', '655', '646', '644', '640', '633', '632', '627', '624', '614', '603', '582', '581', '578', '573', '571', '567', '566', '561', '561', '560', '559', '559', '554', '546', '542', '537', '536', '535', '533', '529', '525', '519', '518', '512', '508', '507', '506', '506', '504', '498', '495', '495', '495', '494', '486', '484', '483', '479', '479', '479', '471', '468', '464', '460', '460', '457', '454', '450', '449', '448', '445', '444', '443', '440', '437', '433', '432', '432', '430', '429', '426', '415', '415', '411', '409']\n"
     ]
    }
   ],
   "source": [
    "#Rating\n",
    "\n",
    "r1 = soup.find_all('div' , class_=\"rankings-block__banner--rating\")\n",
    "r2 = soup.find_all('td' , class_=\"table-body__cell rating\")\n",
    "r = r1+r2\n",
    "\n",
    "rating = []\n",
    "for i in r:\n",
    "    rating.append(i.text.replace(\"\\n\" , \" \"))\n",
    "print(rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['865 v South Africa, 07/04/2021',\n",
       " '911 v England, 12/07/2018',\n",
       " '885 v Sri Lanka, 06/07/2019',\n",
       " '841 v Bangladesh, 05/06/2019',\n",
       " '798 v England, 25/06/2019',\n",
       " '796 v India, 26/03/2021',\n",
       " '778 v South Africa, 07/04/2021',\n",
       " '820 v Australia, 06/07/2019',\n",
       " '880 v Pakistan, 26/01/2017',\n",
       " '808 v Bangladesh, 17/05/2019',\n",
       " '813 v Sri Lanka, 10/03/2019',\n",
       " '799 v India, 09/07/2019',\n",
       " '768 v South Africa, 02/04/2021',\n",
       " '739 v Sri Lanka, 25/05/2021',\n",
       " '824 v Sri Lanka, 13/10/2018',\n",
       " '752 v Pakistan, 22/01/2017',\n",
       " '789 v South Africa, 01/03/2017',\n",
       " '813 v Pakistan, 23/09/2018',\n",
       " '782 v Australia, 11/07/2019',\n",
       " '697 v Netherlands, 04/06/2021',\n",
       " '735 v India, 20/01/2016',\n",
       " '683 v Pakistan, 04/04/2021',\n",
       " '735 v New Zealand, 29/06/2019',\n",
       " '694 v New Zealand, 14/07/2019',\n",
       " '737 v West Indies, 28/07/2018',\n",
       " '720 v Afghanistan, 18/06/2019',\n",
       " '657 v England, 26/03/2021',\n",
       " '644 v India, 02/12/2020',\n",
       " '643 v Pakistan, 04/04/2021',\n",
       " '709 v India, 15/12/2019',\n",
       " '692 v Pakistan, 05/07/2019',\n",
       " '741 v Bangladesh, 08/06/2019',\n",
       " '631 v Bangladesh, 23/03/2021',\n",
       " '634 v Ireland, 12/01/2020',\n",
       " '618 v Zimbabwe, 30/10/2020',\n",
       " '582 v Sri Lanka, 28/05/2021',\n",
       " '596 v Bangladesh, 20/03/2021',\n",
       " '578 v United States, 11/02/2020',\n",
       " '647 v Ireland, 18/03/2018',\n",
       " '667 v New Zealand, 09/02/2012',\n",
       " '707 v England, 07/12/2014',\n",
       " '566 v Bangladesh, 28/05/2021',\n",
       " '561 v England, 28/03/2021',\n",
       " '561 v Pakistan, 03/11/2020',\n",
       " '629 v Afghanistan, 22/06/2019',\n",
       " '567 v Sri Lanka, 12/03/2021',\n",
       " '625 v Sri Lanka, 17/09/2018',\n",
       " '554 v Bangladesh, 28/05/2021',\n",
       " '665 v Bangladesh, 04/03/2014',\n",
       " '631 v Zimbabwe, 30/06/2017',\n",
       " '570 v Zimbabwe, 01/07/2019',\n",
       " '576 v Afghanistan, 22/10/2015',\n",
       " '573 v West Indies, 22/01/2021',\n",
       " '556 v Bangladesh, 05/07/2019',\n",
       " '671 v South Africa, 15/07/2015',\n",
       " '616 v India, 08/03/2019',\n",
       " '594 v Bangladesh, 28/09/2016',\n",
       " '518 v Bangladesh, 28/05/2021',\n",
       " '581 v West Indies, 05/10/2016',\n",
       " '585 v England, 10/06/2018',\n",
       " '520 v Pakistan, 19/01/2018',\n",
       " '518 v West Indies, 09/11/2019',\n",
       " '532 v India, 29/11/2020',\n",
       " '804 v Zimbabwe, 30/11/2003',\n",
       " '519 v India, 22/06/2019',\n",
       " '514 v West Indies, 26/02/2020',\n",
       " '549 v Pakistan, 26/06/2019',\n",
       " '581 v South Africa, 18/01/2009',\n",
       " '545 v Bangladesh, 28/09/2016',\n",
       " '641 v New Zealand, 06/12/2016',\n",
       " '602 v Netherlands, 07/07/2013',\n",
       " '593 v Pakistan, 27/03/2019',\n",
       " '513 v New Zealand, 11/02/2020',\n",
       " '483 v West Indies, 11/11/2019',\n",
       " '487 v United States, 14/12/2019',\n",
       " '478 v Ireland, 08/01/2021',\n",
       " '539 v Sri Lanka, 05/01/2019',\n",
       " '524 v Afghanistan, 18/10/2015',\n",
       " '502 v England, 10/03/2018',\n",
       " '539 v UAE, 12/03/2018',\n",
       " '499 v Australia, 07/03/2020',\n",
       " '459 v New Zealand, 19/06/2019',\n",
       " '450 v Pakistan, 07/04/2021',\n",
       " '599 v West Indies, 04/11/2015',\n",
       " '448 v Bangladesh, 28/05/2021',\n",
       " '445 v Sri Lanka, 14/03/2021',\n",
       " '444 v Pakistan, 07/04/2021',\n",
       " '444 v Namibia, 23/09/2019',\n",
       " '552 v West Indies, 08/10/2014',\n",
       " '515 v Sri Lanka, 19/01/2018',\n",
       " '452 v New Zealand, 23/03/2021',\n",
       " '432 v England, 28/03/2021',\n",
       " '477 v Ireland, 10/03/2019',\n",
       " '430 v Netherlands, 20/05/2021',\n",
       " '667 v Australia, 02/03/2012',\n",
       " '456 v India, 24/10/2018',\n",
       " '416 v Namibia, 23/09/2019',\n",
       " '440 v Ireland, 28/02/2018',\n",
       " '481 v Australia, 26/01/2018',\n",
       " '415 v Australia, 16/09/2020']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Career best Rating\n",
    "cb1 = soup.find_all('span' , class_=\"rankings-block__career-best-text\")\n",
    "cb2 = soup.find_all('td' , class_=\"table-body__cell u-text-right u-hide-phablet\")\n",
    "cb = cb1+cb2\n",
    "\n",
    "career_best = []\n",
    "for i in cb:\n",
    "    career_best.append(i.text.strip())\n",
    "career_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Career best</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Babar Azam</td>\n",
       "      <td>PAK</td>\n",
       "      <td>865</td>\n",
       "      <td>865 v South Africa, 07/04/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>IND</td>\n",
       "      <td>857</td>\n",
       "      <td>911 v England, 12/07/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rohit Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>825</td>\n",
       "      <td>885 v Sri Lanka, 06/07/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ross Taylor</td>\n",
       "      <td>NZ</td>\n",
       "      <td>801</td>\n",
       "      <td>841 v Bangladesh, 05/06/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aaron Finch</td>\n",
       "      <td>AUS</td>\n",
       "      <td>791</td>\n",
       "      <td>798 v England, 25/06/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jonny Bairstow</td>\n",
       "      <td>ENG</td>\n",
       "      <td>785</td>\n",
       "      <td>796 v India, 26/03/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fakhar Zaman</td>\n",
       "      <td>PAK</td>\n",
       "      <td>778</td>\n",
       "      <td>778 v South Africa, 07/04/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Francois du Plessis</td>\n",
       "      <td>SA</td>\n",
       "      <td>778</td>\n",
       "      <td>820 v Australia, 06/07/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>David Warner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>773</td>\n",
       "      <td>880 v Pakistan, 26/01/2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Shai Hope</td>\n",
       "      <td>WI</td>\n",
       "      <td>773</td>\n",
       "      <td>808 v Bangladesh, 17/05/2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Name                        Team Rating  \\\n",
       "0             Babar Azam    PAK                         865   \n",
       "1           Virat Kohli                          IND    857   \n",
       "2          Rohit Sharma                          IND    825   \n",
       "3           Ross Taylor                           NZ    801   \n",
       "4           Aaron Finch                          AUS    791   \n",
       "5        Jonny Bairstow                          ENG    785   \n",
       "6          Fakhar Zaman                          PAK    778   \n",
       "7   Francois du Plessis                           SA    778   \n",
       "8          David Warner                          AUS    773   \n",
       "9             Shai Hope                           WI    773   \n",
       "\n",
       "                      Career best  \n",
       "0  865 v South Africa, 07/04/2021  \n",
       "1       911 v England, 12/07/2018  \n",
       "2     885 v Sri Lanka, 06/07/2019  \n",
       "3    841 v Bangladesh, 05/06/2019  \n",
       "4       798 v England, 25/06/2019  \n",
       "5         796 v India, 26/03/2021  \n",
       "6  778 v South Africa, 07/04/2021  \n",
       "7     820 v Australia, 06/07/2019  \n",
       "8      880 v Pakistan, 26/01/2017  \n",
       "9    808 v Bangladesh, 17/05/2019  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "men_odi = pd.DataFrame({})\n",
    "men_odi['Name'] = player_name\n",
    "men_odi['Team'] = team_name\n",
    "men_odi['Rating'] = rating\n",
    "men_odi[\"Career best\"] = career_best\n",
    "men_odi.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iii) Top 10 ODI bowlers along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling\"\n",
    "r = requests.get(url, 'html.parser')\n",
    "soup = BeautifulSoup(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Trent Boult', ' Mehedi Hasan ', ' Mujeeb Ur Rahman ', ' Matt Henry ', ' Jasprit Bumrah ', ' Kagiso Rabada ', ' Chris Woakes ', ' Josh Hazlewood ', ' Pat Cummins ', ' Mustafizur Rahman ', ' Mohammad Amir ', ' Shaheen Afridi ', ' Bhuvneshwar Kumar ', ' Jofra Archer ', ' Rashid Khan ', ' Adam Zampa ', ' Lachlan Ferguson ', ' Shakib Al Hasan ', ' Mitchell Starc ', ' Lungi Ngidi ', ' Mohammad Nabi ', ' Mark Wood ', ' Akila Dananjaya ', ' Yuzvendra Chahal ', ' Mitchell Santner ', ' Mohammad Shami ', ' Alzarri Joseph ', ' Kuldeep Yadav ', ' Ravindra Jadeja ', ' Sheldon Cottrell ', ' Liam Plunkett ', ' Dushmantha Chameera ', ' Andy McBrine ', ' Ahmed Raza ', ' Adil Rashid ', ' Shadab Khan ', ' Dwaine Pretorius ', ' Colin de Grandhomme ', ' Andile Phehlukwayo ', ' Tim Southee ', ' Ish Sodhi ', ' Imad Wasim ', ' Mark Watt ', ' Tendai Chatara ', ' Usman Khan ', ' Jhye Richardson ', ' Moeen Ali ', ' Rohan Mustafa ', ' Mashrafe Mortaza ', ' David Willey ', ' Simi Singh ', ' Wanindu De Silva ', ' Mohammad Mohammad Saifuddin ', ' Hasan Ali ', ' Nuwan Pradeep ', ' Tabraiz Shamsi ', ' Nathan Coulter-Nile ', ' Faheem Ashraf ', ' Safyaan Sharif ', ' Jason Holder ', ' Chris Morris ', ' Nathan Lyon ', ' Jimmy Neesham ', ' Kyle Jarvis ', ' Suranga Lakmal ', ' Wahab Riaz ', ' Junaid Khan ', ' Sikandar Raza ', ' Ben Stokes ', ' Kemar Roach ', ' Dawlat Zadran ', ' Josh Davey ', ' Sean Williams ', ' Anrich Nortje ', ' Kane Richardson ', ' Aftab Alam ', ' Yasir Shah ', ' Shardul Thakur ', ' Jason Behrendorff ', ' Dhananjaya de Silva ', ' Rubel Hossain ', ' Hardik Pandya ', ' Craig Young ', ' Gulbadin Naib ', ' Barry McCarthy ', ' Mitchell Marsh ', ' Alasdair Evans ', ' Tom Curran ', ' Taskin Ahmed ', ' Ashley Nurse ', ' Hamid Hassan ', ' Blessing Muzarabani ', ' Marcus Stoinis ', ' Lakshan Sandakan ', ' Taijul Islam ', ' Ashton Agar ', ' Mohammad Nawaz ', ' Donald Tiripano ', ' George Dockrell ', ' Bradley Wheal ']\n"
     ]
    }
   ],
   "source": [
    "#Name\n",
    "\n",
    "name1 = soup.find_all('div' , class_=\"rankings-block__banner--name-large\")\n",
    "name2 = soup.find_all('td' , class_=\"table-body__cell rankings-table__name name\")\n",
    "name = name1+name2\n",
    "\n",
    "player_name = []\n",
    "for i in name:\n",
    "    player_name.append(i.text.replace(\"\\n\" , \" \"))\n",
    "print(player_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['  NZ                     ', 'BAN', 'AFG', 'NZ', 'IND', 'SA', 'ENG', 'AUS', 'AUS', 'BAN', 'PAK', 'PAK', 'IND', 'ENG', 'AFG', 'AUS', 'NZ', 'BAN', 'AUS', 'SA', 'AFG', 'ENG', 'SL', 'IND', 'NZ', 'IND', 'WI', 'IND', 'IND', 'WI', 'ENG', 'SL', 'IRE', 'UAE', 'ENG', 'PAK', 'SA', 'NZ', 'SA', 'NZ', '', 'PAK', 'SCO', 'ZIM', 'PAK', 'AUS', 'ENG', 'UAE', 'BAN', 'ENG', 'IRE', 'SL', 'BAN', 'PAK', 'SL', 'SA', 'AUS', 'PAK', 'SCO', 'WI', 'SA', 'AUS', 'NZ', 'ZIM', 'SL', 'PAK', 'PAK', 'ZIM', 'ENG', 'WI', 'AFG', 'SCO', 'ZIM', 'SA', 'AUS', 'AFG', 'PAK', 'IND', 'AUS', 'SL', 'BAN', 'IND', 'IRE', 'AFG', 'IRE', 'AUS', 'SCO', 'ENG', 'BAN', 'WI', 'AFG', 'ZIM', 'AUS', 'SL', 'BAN', 'AUS', 'PAK', 'ZIM', 'IRE', 'SCO']\n"
     ]
    }
   ],
   "source": [
    "#For Team\n",
    "\n",
    "team1 = soup.find_all('div' , class_=\"rankings-block__banner--nationality\")\n",
    "team2 = soup.find_all('span' , class_=\"table-body__logo-text\")\n",
    "team = team1+team2\n",
    "\n",
    "team_name = []\n",
    "for i in team:\n",
    "    team_name.append(i.text.replace(\"\\n\" , \" \"))\n",
    "print(team_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['737', '713', '708', '691', '690', '666', '665', '660', '646', '645', '638', '634', '632', '627', '626', '623', '619', '613', '611', '606', '596', '594', '594', '584', '583', '574', '569', '564', '559', '558', '546', '533', '533', '531', '529', '523', '515', '508', '506', '500', '496', '495', '490', '490', '489', '488', '486', '477', '476', '475', '474', '473', '473', '473', '473', '470', '470', '469', '467', '465', '462', '462', '458', '458', '456', '454', '449', '443', '442', '431', '427', '427', '426', '425', '422', '422', '418', '411', '410', '410', '406', '403', '403', '399', '397', '395', '394', '391', '391', '388', '387', '387', '383', '381', '379', '377', '376', '373', '370', '368']\n"
     ]
    }
   ],
   "source": [
    "#Rating\n",
    "\n",
    "r1 = soup.find_all('div' , class_=\"rankings-block__banner--rating\")\n",
    "r2 = soup.find_all('td' , class_=\"table-body__cell rating\")\n",
    "r = r1+r2\n",
    "\n",
    "rating = []\n",
    "for i in r:\n",
    "    rating.append(i.text.replace(\"\\n\" , \" \"))\n",
    "print(rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['770 v West Indies, 22/06/2019',\n",
       " '725 v Sri Lanka, 25/05/2021',\n",
       " '712 v Ireland, 24/01/2021',\n",
       " '691 v Bangladesh, 26/03/2021',\n",
       " '841 v West Indies, 01/11/2018',\n",
       " '724 v England, 29/05/2017',\n",
       " '676 v New Zealand, 14/07/2019',\n",
       " '733 v England, 26/01/2018',\n",
       " '729 v Pakistan, 12/06/2019',\n",
       " '695 v West Indies, 14/12/2018',\n",
       " '663 v Sri Lanka, 02/10/2019',\n",
       " '634 v South Africa, 07/04/2021',\n",
       " '657 v West Indies, 17/10/2014',\n",
       " '642 v Australia, 13/09/2020',\n",
       " '806 v Pakistan, 21/09/2018',\n",
       " '623 v India, 02/12/2020',\n",
       " '668 v West Indies, 22/06/2019',\n",
       " '717 v Zimbabwe, 05/11/2009',\n",
       " '783 v New Zealand, 29/03/2015',\n",
       " '621 v Australia, 04/03/2020',\n",
       " '653 v Zimbabwe, 26/02/2017',\n",
       " '615 v Sri Lanka, 21/06/2019',\n",
       " '651 v England, 23/10/2018',\n",
       " '730 v New Zealand, 23/01/2019',\n",
       " '663 v England, 25/02/2018',\n",
       " '654 v Bangladesh, 19/03/2015',\n",
       " '569 v Sri Lanka, 14/03/2021',\n",
       " '765 v New Zealand, 26/01/2019',\n",
       " '738 v Zimbabwe, 01/08/2013',\n",
       " '581 v Sri Lanka, 26/02/2020',\n",
       " '646 v West Indies, 29/09/2017',\n",
       " '533 v Bangladesh, 28/05/2021',\n",
       " '570 v Zimbabwe, 01/07/2019',\n",
       " '531 v Ireland, 18/01/2021',\n",
       " '687 v Sri Lanka, 20/10/2018',\n",
       " '607 v South Africa, 22/01/2019',\n",
       " '539 v Australia, 06/07/2019',\n",
       " '522 v India, 11/02/2020',\n",
       " '613 v Pakistan, 30/01/2019',\n",
       " '638 v England, 20/02/2015',\n",
       " '',\n",
       " '570 v England, 19/05/2019',\n",
       " '495 v United States, 14/12/2019',\n",
       " '562 v Ireland, 07/03/2015',\n",
       " '504 v Sri Lanka, 02/10/2019',\n",
       " '548 v Pakistan, 24/03/2019',\n",
       " '629 v Australia, 24/06/2018',\n",
       " '477 v Ireland, 18/01/2021',\n",
       " '653 v Zimbabwe, 23/01/2009',\n",
       " '551 v Sri Lanka, 02/07/2016',\n",
       " '474 v Netherlands, 07/06/2021',\n",
       " '473 v Bangladesh, 28/05/2021',\n",
       " '496 v West Indies, 25/01/2021',\n",
       " '766 v New Zealand, 06/01/2018',\n",
       " '506 v England, 13/10/2018',\n",
       " '486 v Australia, 04/03/2020',\n",
       " '514 v Bangladesh, 20/06/2019',\n",
       " '477 v South Africa, 02/04/2021',\n",
       " '542 v England, 10/06/2018',\n",
       " '486 v Sri Lanka, 10/03/2021',\n",
       " '507 v Sri Lanka, 03/06/2017',\n",
       " '510 v South Africa, 06/07/2019',\n",
       " '458 v Bangladesh, 26/03/2021',\n",
       " '473 v Ireland, 07/07/2019',\n",
       " '594 v Bangladesh, 25/01/2018',\n",
       " '522 v England, 13/11/2015',\n",
       " '655 v Sri Lanka, 27/12/2013',\n",
       " '494 v UAE, 16/04/2019',\n",
       " '474 v New Zealand, 03/07/2019',\n",
       " '650 v Pakistan, 19/07/2013',\n",
       " '574 v Zimbabwe, 02/01/2016',\n",
       " '436 v UAE, 15/12/2019',\n",
       " '474 v Sri Lanka, 30/06/2017',\n",
       " '427 v Pakistan, 04/04/2021',\n",
       " '448 v India, 17/01/2020',\n",
       " '456 v South Africa, 15/06/2019',\n",
       " '487 v Zimbabwe, 20/07/2018',\n",
       " '411 v England, 28/03/2021',\n",
       " '439 v England, 11/07/2019',\n",
       " '412 v Bangladesh, 23/05/2021',\n",
       " '514 v Pakistan, 01/12/2011',\n",
       " '552 v South Africa, 16/02/2018',\n",
       " '403 v Netherlands, 07/06/2021',\n",
       " '472 v Ireland, 21/05/2019',\n",
       " '448 v West Indies, 09/01/2020',\n",
       " '511 v New Zealand, 04/12/2016',\n",
       " '421 v England, 10/06/2018',\n",
       " '404 v Pakistan, 17/05/2019',\n",
       " '456 v Sri Lanka, 28/03/2017',\n",
       " '568 v India, 27/10/2018',\n",
       " '478 v England, 13/03/2015',\n",
       " '387 v Pakistan, 03/11/2020',\n",
       " '426 v England, 25/06/2019',\n",
       " '383 v Bangladesh, 25/05/2021',\n",
       " '397 v Zimbabwe, 06/03/2020',\n",
       " '377 v India, 02/12/2020',\n",
       " '376 v South Africa, 07/04/2021',\n",
       " '373 v Pakistan, 03/11/2020',\n",
       " '589 v West Indies, 16/02/2015',\n",
       " '385 v Sri Lanka, 21/05/2019']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Career best Rating\n",
    "cb1 = soup.find_all('span' , class_=\"rankings-block__career-best-text\")\n",
    "cb2 = soup.find_all('td' , class_=\"table-body__cell u-text-right u-hide-phablet\")\n",
    "cb = cb1+cb2\n",
    "\n",
    "career_best = []\n",
    "for i in cb:\n",
    "    career_best.append(i.text.strip())\n",
    "career_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Career best</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trent Boult</td>\n",
       "      <td>NZ</td>\n",
       "      <td>737</td>\n",
       "      <td>770 v West Indies, 22/06/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mehedi Hasan</td>\n",
       "      <td>BAN</td>\n",
       "      <td>713</td>\n",
       "      <td>725 v Sri Lanka, 25/05/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mujeeb Ur Rahman</td>\n",
       "      <td>AFG</td>\n",
       "      <td>708</td>\n",
       "      <td>712 v Ireland, 24/01/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Matt Henry</td>\n",
       "      <td>NZ</td>\n",
       "      <td>691</td>\n",
       "      <td>691 v Bangladesh, 26/03/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jasprit Bumrah</td>\n",
       "      <td>IND</td>\n",
       "      <td>690</td>\n",
       "      <td>841 v West Indies, 01/11/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Kagiso Rabada</td>\n",
       "      <td>SA</td>\n",
       "      <td>666</td>\n",
       "      <td>724 v England, 29/05/2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Chris Woakes</td>\n",
       "      <td>ENG</td>\n",
       "      <td>665</td>\n",
       "      <td>676 v New Zealand, 14/07/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Josh Hazlewood</td>\n",
       "      <td>AUS</td>\n",
       "      <td>660</td>\n",
       "      <td>733 v England, 26/01/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Pat Cummins</td>\n",
       "      <td>AUS</td>\n",
       "      <td>646</td>\n",
       "      <td>729 v Pakistan, 12/06/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mustafizur Rahman</td>\n",
       "      <td>BAN</td>\n",
       "      <td>645</td>\n",
       "      <td>695 v West Indies, 14/12/2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Name                       Team Rating  \\\n",
       "0          Trent Boult    NZ                         737   \n",
       "1        Mehedi Hasan                         BAN    713   \n",
       "2    Mujeeb Ur Rahman                         AFG    708   \n",
       "3          Matt Henry                          NZ    691   \n",
       "4      Jasprit Bumrah                         IND    690   \n",
       "5       Kagiso Rabada                          SA    666   \n",
       "6        Chris Woakes                         ENG    665   \n",
       "7      Josh Hazlewood                         AUS    660   \n",
       "8         Pat Cummins                         AUS    646   \n",
       "9   Mustafizur Rahman                         BAN    645   \n",
       "\n",
       "                     Career best  \n",
       "0  770 v West Indies, 22/06/2019  \n",
       "1    725 v Sri Lanka, 25/05/2021  \n",
       "2      712 v Ireland, 24/01/2021  \n",
       "3   691 v Bangladesh, 26/03/2021  \n",
       "4  841 v West Indies, 01/11/2018  \n",
       "5      724 v England, 29/05/2017  \n",
       "6  676 v New Zealand, 14/07/2019  \n",
       "7      733 v England, 26/01/2018  \n",
       "8     729 v Pakistan, 12/06/2019  \n",
       "9  695 v West Indies, 14/12/2018  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "men_odi_bowl = pd.DataFrame({})\n",
    "men_odi_bowl['Name'] = player_name\n",
    "men_odi_bowl['Team'] = team_name\n",
    "men_odi_bowl['Rating'] = rating\n",
    "men_odi_bowl[\"Career best\"] = career_best\n",
    "men_odi_bowl.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.)\n",
    "\n",
    "# i.) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "icc_women = \"https://www.icc-cricket.com/rankings/womens/team-rankings/odi\"\n",
    "r = requests.get(icc_women)\n",
    "soup = BeautifulSoup(r.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank1 = soup.find_all('td' , class_= 'rankings-block__banner--pos')\n",
    "rank2 = soup.find_all('td' , class_= 'table-body__cell table-body__cell--position u-text-right')\n",
    "rank = rank1 + rank2\n",
    "\n",
    "ranking = []\n",
    "for i in rank:\n",
    "    ranking.append(i.text.replace(\"\\n\" , \"\"))\n",
    "ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['  Australia AUS ',\n",
       " '  South Africa SA ',\n",
       " '  England ENG ',\n",
       " '  India IND ',\n",
       " '  New Zealand NZ ',\n",
       " '  West Indies WI ',\n",
       " '  Pakistan PAK ',\n",
       " '  Bangladesh BAN ',\n",
       " '  Sri Lanka SL ',\n",
       " '  Ireland IRE ']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team1 = soup.find_all('td' , class_= \"rankings-block__banner--team-name\")\n",
    "\n",
    "team2 = soup.find_all('td' , class_= \"table-body__cell rankings-table__team\")\n",
    "\n",
    "teams = team1 + team2\n",
    "\n",
    "country = []\n",
    "for i in teams:\n",
    "    country.append(i.text.replace(\"\\n\",\" \"))\n",
    "country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['18',\n",
       " '24',\n",
       " '2,828',\n",
       " '17',\n",
       " '1,993',\n",
       " '20',\n",
       " '2,226',\n",
       " '21',\n",
       " '1,947',\n",
       " '12',\n",
       " '1,025',\n",
       " '15',\n",
       " '1,101',\n",
       " '5',\n",
       " '306',\n",
       " '11',\n",
       " '519',\n",
       " '2',\n",
       " '25']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches1 = soup.find_all('td' , class_='rankings-block__banner--matches')\n",
    "matches2 = soup.find_all('td' , class_='table-body__cell u-center-text')\n",
    "match = matches1 + matches2\n",
    "matches = []\n",
    "for i in match:\n",
    "    matches.append(i.text.replace(\"\\n\",\"  \"))\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['18', '24', '17', '20', '21', '12', '15', '5', '11', '519', '2', '25']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del matches[2:16:2]\n",
    "\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "del matches[-3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "del matches[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2,955',\n",
       " '24',\n",
       " '2,828',\n",
       " '17',\n",
       " '1,993',\n",
       " '20',\n",
       " '2,226',\n",
       " '21',\n",
       " '1,947',\n",
       " '12',\n",
       " '1,025',\n",
       " '15',\n",
       " '1,101',\n",
       " '5',\n",
       " '306',\n",
       " '11',\n",
       " '519',\n",
       " '2',\n",
       " '25']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Points\n",
    "p1 = soup.find_all('td' , class_=\"rankings-block__banner--points\")\n",
    "p2 = soup.find_all('td' , class_=\"table-body__cell u-center-text\")\n",
    "p = p1 + p2\n",
    "points = []\n",
    "for i in p:\n",
    "    points.append(i.text.replace(\"\\n\",\"  \"))\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2,955',\n",
       " '2,828',\n",
       " '1,993',\n",
       " '2,226',\n",
       " '1,947',\n",
       " '1,025',\n",
       " '1,101',\n",
       " '306',\n",
       " '519',\n",
       " '25']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del points[1:18:2]\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['164', '118', '117', '111', '93', '85', '73', '61', '47', '13']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ratings\n",
    "rating1 = soup.find_all('td' , class_=\"rankings-block__banner--rating u-text-right\")\n",
    "rating2 = soup.find_all('td' , class_=\"table-body__cell u-text-right rating\")\n",
    "ratings = rating1 + rating2\n",
    "rating = []\n",
    "for i in ratings:\n",
    "    rating.append(i.text.strip())\n",
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ranking</th>\n",
       "      <th>Country</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Australia AUS</td>\n",
       "      <td>18</td>\n",
       "      <td>2,955</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>South Africa SA</td>\n",
       "      <td>24</td>\n",
       "      <td>2,828</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>England ENG</td>\n",
       "      <td>17</td>\n",
       "      <td>1,993</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>India IND</td>\n",
       "      <td>20</td>\n",
       "      <td>2,226</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>New Zealand NZ</td>\n",
       "      <td>21</td>\n",
       "      <td>1,947</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Indies WI</td>\n",
       "      <td>12</td>\n",
       "      <td>1,025</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Pakistan PAK</td>\n",
       "      <td>15</td>\n",
       "      <td>1,101</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Bangladesh BAN</td>\n",
       "      <td>5</td>\n",
       "      <td>306</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Sri Lanka SL</td>\n",
       "      <td>11</td>\n",
       "      <td>519</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Ireland IRE</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ranking             Country Matches Points Ratings\n",
       "0       1      Australia AUS       18  2,955     164\n",
       "1       2    South Africa SA       24  2,828     118\n",
       "2       3        England ENG       17  1,993     117\n",
       "3       4          India IND       20  2,226     111\n",
       "4       5     New Zealand NZ       21  1,947      93\n",
       "5       6     West Indies WI       12  1,025      85\n",
       "6       7       Pakistan PAK       15  1,101      73\n",
       "7       8     Bangladesh BAN        5    306      61\n",
       "8       9       Sri Lanka SL       11    519      47\n",
       "9      10        Ireland IRE        2     25      13"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({})\n",
    "df['Ranking'] = ranking\n",
    "df['Country'] = country\n",
    "df['Matches'] = matches\n",
    "df['Points'] = points\n",
    "df['Ratings'] = rating\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ii.) Top 10 women’s ODI players along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting\"\n",
    "r = requests.get(url, 'html.parser')\n",
    "soup = BeautifulSoup(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tammy Beaumont', ' Lizelle Lee ', ' Alyssa Healy ', ' Stafanie Taylor ', ' Meg Lanning ', ' Amy Satterthwaite ', ' Smriti Mandhana ', ' Mithali Raj ', ' Natalie Sciver ', ' Laura Wolvaardt ', ' Ellyse Perry ', ' Chamari Athapaththu ', ' Heather Knight ', ' Rachael Haynes ', ' Harmanpreet Kaur ', ' Mignon du Preez ', ' Beth Mooney ', ' Poonam Raut ', ' Suzie Bates ', ' Sophie Devine ', ' Deepti Sharma ', ' Marizanne Kapp ', ' Nahida Khan ', ' Amy Jones ', ' Javeria Khan ', ' Bismah Maroof ', ' Dane van Niekerk ', ' Hayley Matthews ', ' Nicole Bolton ', ' Fargana Hoque ', ' Ashleigh Gardner ', ' Rumana Ahmed ', ' Chloe-Lesleigh Tryon ', ' Katie Perkins ', ' Aliya Riaz ', ' Danielle Wyatt ', ' Sune Luus ', ' Amelia Kerr ', ' Jess Jonassen ', ' Katherine Brunt ', ' Nida Dar ', ' Trisha Chetty ', ' Katey Martin ', ' Harshitha Madavi ', ' Brooke Halliday ', ' Fran Wilson ', ' Jemimah Rodriques ', ' Shikha Pandey ', ' Maddie Green ', ' Shemaine Campbelle ', ' Dilani Manodara ', ' Nigar Sultana ', ' Umaima Sohail ', ' Priya Punia ', ' Lara Goodall ', ' Lauren Winfield ', ' Jhulan Goswami ', ' Chedean Nation ', ' Rachel Priest ', ' Kyshona Knight ', ' Kycia Knight ', ' Lauren Down ', ' Sidra Ameen ', ' Nilakshi Silva ', ' Nicola Carey ', ' Hayley Jensen ', ' Sheneta Grimmond ', ' Salma Khatun ', ' Taniya Bhatia ', ' Georgia Wareham ', ' Poonam Yadav ', ' Anne Bosch ', ' Andrie Steyn ', ' Avanthika Mendis ', ' Anya Shrubsole ', ' Natasha McLean ', ' Sharmin Supta ', ' Rajeshwari Gayakwad ', ' Leigh Kasperek ', ' Anushka Sanjeewani ', ' Kate Cross ', ' Inoka Ranaweera ', ' Lea Tahuhu ', ' Stacy-Ann King ', ' Megan Schutt ', ' Oshadi Ranasinghe ', ' Nashra Sandhu ', ' Sushma Verma ', ' Chinelle Henry ', ' Shamilia Connell ', ' Sanjida Islam ', ' Jess Kerr ', ' Hannah Rowe ', ' Shabnim Ismail ', ' Afy Fletcher ', ' Sophie Ecclestone ', ' Diana Baig ', ' Sidra Nawaz ', ' Panna Ghosh ', ' Ama Kanchana ']\n"
     ]
    }
   ],
   "source": [
    "#Fetching Player_Name\n",
    "\n",
    "name1 = soup.find_all('div' , class_=\"rankings-block__banner--name-large\")\n",
    "name2 = soup.find_all('td' , class_=\"table-body__cell rankings-table__name name\")\n",
    "name = name1+name2\n",
    "player_name = []\n",
    "for i in name:\n",
    "    player_name.append(i.text.replace(\"\\n\" , \" \"))\n",
    "print(player_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['  ENG                     ', 'SA', 'AUS', 'WI', 'AUS', 'NZ', 'IND', 'IND', 'ENG', 'SA', 'AUS', 'SL', 'ENG', 'AUS', 'IND', 'SA', 'AUS', 'IND', 'NZ', 'NZ', 'IND', 'SA', 'PAK', 'ENG', 'PAK', 'PAK', 'SA', 'WI', 'AUS', 'BAN', 'AUS', 'BAN', 'SA', 'NZ', 'PAK', 'ENG', 'SA', 'NZ', 'AUS', 'ENG', 'PAK', 'SA', 'NZ', 'SL', 'NZ', 'ENG', 'IND', 'IND', 'NZ', 'WI', 'SL', 'BAN', 'PAK', 'IND', 'SA', 'ENG', 'IND', 'WI', 'NZ', 'WI', 'WI', 'NZ', 'PAK', 'SL', 'AUS', 'NZ', 'WI', 'BAN', 'IND', 'AUS', 'IND', 'SA', 'SA', 'SL', 'ENG', 'WI', 'BAN', 'IND', 'NZ', 'SL', 'ENG', 'SL', 'NZ', 'WI', 'AUS', 'SL', 'PAK', 'IND', 'WI', 'WI', 'BAN', 'NZ', 'NZ', 'SA', 'WI', 'ENG', 'PAK', 'PAK', 'BAN', 'SL']\n"
     ]
    }
   ],
   "source": [
    "#For Team\n",
    "\n",
    "team1 = soup.find_all('div' , class_=\"rankings-block__banner--nationality\")\n",
    "team2 = soup.find_all('span' , class_=\"table-body__logo-text\")\n",
    "team = team1+team2\n",
    "team_name = []\n",
    "for i in team:\n",
    "    team_name.append(i.text.replace(\"\\n\" , \" \"))\n",
    "print(team_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['765', '758', '756', '746', '723', '715', '710', '709', '685', '683', '679', '667', '666', '657', '636', '620', '600', '593', '577', '573', '568', '560', '560', '536', '536', '520', '498', '461', '456', '445', '440', '437', '437', '413', '410', '404', '398', '396', '380', '361', '360', '359', '357', '353', '350', '341', '337', '335', '320', '319', '319', '317', '310', '305', '305', '302', '294', '292', '285', '281', '276', '264', '264', '261', '259', '256', '252', '244', '240', '239', '236', '234', '234', '226', '225', '224', '221', '220', '219', '211', '208', '205', '204', '201', '195', '195', '192', '190', '188', '186', '181', '179', '179', '178', '175', '172', '170', '168', '166', '161']\n"
     ]
    }
   ],
   "source": [
    "#Rating\n",
    "\n",
    "r1 = soup.find_all('div' , class_=\"rankings-block__banner--rating\")\n",
    "r2 = soup.find_all('td' , class_=\"table-body__cell rating\")\n",
    "r = r1+r2\n",
    "rating = []\n",
    "for i in r:\n",
    "    rating.append(i.text.replace(\"\\n\" , \" \"))\n",
    "print(rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['765 v New Zealand, 28/02/2021',\n",
       " '773 v India, 14/03/2021',\n",
       " '756 v New Zealand, 10/04/2021',\n",
       " '765 v India, 02/03/2012',\n",
       " '834 v New Zealand, 24/02/2016',\n",
       " '756 v Australia, 02/03/2017',\n",
       " '797 v England, 28/02/2019',\n",
       " '839 v Australia, 24/12/2004',\n",
       " '712 v India, 25/02/2019',\n",
       " '725 v India, 07/03/2021',\n",
       " '766 v West Indies, 11/09/2019',\n",
       " '691 v South Africa, 14/02/2019',\n",
       " '693 v West Indies, 06/06/2019',\n",
       " '680 v New Zealand, 07/04/2021',\n",
       " '679 v South Africa, 28/11/2014',\n",
       " '620 v India, 17/03/2021',\n",
       " '613 v Sri Lanka, 05/10/2019',\n",
       " '606 v South Africa, 14/03/2021',\n",
       " '775 v Australia, 24/02/2016',\n",
       " '678 v Australia, 03/03/2019',\n",
       " '622 v South Africa, 09/10/2019',\n",
       " '569 v Pakistan, 23/01/2021',\n",
       " '603 v England, 14/12/2019',\n",
       " '564 v West Indies, 13/06/2019',\n",
       " '573 v South Africa, 15/03/2015',\n",
       " '570 v New Zealand, 13/11/2016',\n",
       " '677 v Sri Lanka, 11/02/2019',\n",
       " '522 v England, 09/06/2019',\n",
       " '687 v India, 15/03/2018',\n",
       " '446 v Pakistan, 04/11/2019',\n",
       " '452 v New Zealand, 07/04/2021',\n",
       " '439 v Pakistan, 04/11/2019',\n",
       " '548 v Pakistan, 12/05/2019',\n",
       " '503 v South Africa, 25/01/2020',\n",
       " '410 v South Africa, 26/01/2021',\n",
       " '465 v Pakistan, 09/12/2019',\n",
       " '469 v England, 05/07/2017',\n",
       " '409 v Australia, 07/04/2021',\n",
       " '410 v England, 07/07/2019',\n",
       " '403 v India, 22/02/2019',\n",
       " '361 v South Africa, 23/01/2021',\n",
       " '585 v Ireland, 09/08/2016',\n",
       " '483 v Australia, 05/03/2017',\n",
       " '356 v Australia, 09/10/2019',\n",
       " '350 v Australia, 10/04/2021',\n",
       " '355 v India, 09/04/2018',\n",
       " '411 v West Indies, 06/11/2019',\n",
       " '383 v South Africa, 14/10/2019',\n",
       " '327 v Australia, 07/04/2021',\n",
       " '403 v New Zealand, 14/09/2014',\n",
       " '419 v West Indies, 15/10/2017',\n",
       " '336 v Pakistan, 02/11/2019',\n",
       " '337 v South Africa, 23/01/2021',\n",
       " '305 v South Africa, 17/03/2021',\n",
       " '320 v India, 14/03/2021',\n",
       " '395 v Australia, 22/10/2017',\n",
       " '430 v New Zealand, 28/06/2015',\n",
       " '312 v India, 01/11/2019',\n",
       " '589 v Sri Lanka, 07/11/2015',\n",
       " '313 v Australia, 11/09/2019',\n",
       " '404 v Sri Lanka, 18/05/2015',\n",
       " '275 v Australia, 04/04/2021',\n",
       " '319 v South Africa, 09/05/2019',\n",
       " '279 v Australia, 07/10/2019',\n",
       " '259 v New Zealand, 10/04/2021',\n",
       " '271 v England, 23/02/2021',\n",
       " '268 v India, 01/11/2019',\n",
       " '366 v South Africa, 22/09/2013',\n",
       " '291 v West Indies, 06/11/2019',\n",
       " '239 v New Zealand, 10/04/2021',\n",
       " '260 v South Africa, 11/10/2019',\n",
       " '234 v India, 17/03/2021',\n",
       " '378 v Ireland, 19/05/2017',\n",
       " '408 v India, 21/01/2014',\n",
       " '249 v West Indies, 09/06/2019',\n",
       " '243 v New Zealand, 08/10/2013',\n",
       " '226 v Pakistan, 02/11/2019',\n",
       " '229 v South Africa, 14/03/2021',\n",
       " '259 v South Africa, 25/01/2020',\n",
       " '222 v Australia, 07/10/2019',\n",
       " '223 v Pakistan, 12/12/2019',\n",
       " '230 v Australia, 29/06/2017',\n",
       " '204 v Australia, 10/04/2021',\n",
       " '390 v India, 29/02/2012',\n",
       " '209 v Sri Lanka, 23/09/2016',\n",
       " '206 v England, 21/03/2019',\n",
       " '228 v Bangladesh, 02/11/2019',\n",
       " '261 v Australia, 18/03/2018',\n",
       " '196 v Australia, 11/09/2019',\n",
       " '230 v Pakistan, 09/02/2019',\n",
       " '192 v South Africa, 04/05/2018',\n",
       " '179 v Australia, 10/04/2021',\n",
       " '191 v Australia, 04/04/2021',\n",
       " '290 v Ireland, 14/01/2014',\n",
       " '182 v India, 06/11/2019',\n",
       " '198 v Australia, 02/07/2019',\n",
       " '170 v South Africa, 26/01/2021',\n",
       " '170 v New Zealand, 13/11/2016',\n",
       " '170 v Pakistan, 02/11/2019',\n",
       " '183 v Pakistan, 22/03/2018']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Career best Rating\n",
    "cb1 = soup.find_all('span' , class_=\"rankings-block__career-best-text\")\n",
    "cb2 = soup.find_all('td' , class_=\"table-body__cell u-text-right u-hide-phablet\")\n",
    "cb = cb1+cb2\n",
    "career_best = []\n",
    "for i in cb:\n",
    "    career_best.append(i.text.strip())\n",
    "career_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Career best</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tammy Beaumont</td>\n",
       "      <td>ENG</td>\n",
       "      <td>765</td>\n",
       "      <td>765 v New Zealand, 28/02/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lizelle Lee</td>\n",
       "      <td>SA</td>\n",
       "      <td>758</td>\n",
       "      <td>773 v India, 14/03/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alyssa Healy</td>\n",
       "      <td>AUS</td>\n",
       "      <td>756</td>\n",
       "      <td>756 v New Zealand, 10/04/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stafanie Taylor</td>\n",
       "      <td>WI</td>\n",
       "      <td>746</td>\n",
       "      <td>765 v India, 02/03/2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Meg Lanning</td>\n",
       "      <td>AUS</td>\n",
       "      <td>723</td>\n",
       "      <td>834 v New Zealand, 24/02/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Amy Satterthwaite</td>\n",
       "      <td>NZ</td>\n",
       "      <td>715</td>\n",
       "      <td>756 v Australia, 02/03/2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Smriti Mandhana</td>\n",
       "      <td>IND</td>\n",
       "      <td>710</td>\n",
       "      <td>797 v England, 28/02/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mithali Raj</td>\n",
       "      <td>IND</td>\n",
       "      <td>709</td>\n",
       "      <td>839 v Australia, 24/12/2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>685</td>\n",
       "      <td>712 v India, 25/02/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Laura Wolvaardt</td>\n",
       "      <td>SA</td>\n",
       "      <td>683</td>\n",
       "      <td>725 v India, 07/03/2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Name                        Team Rating  \\\n",
       "0       Tammy Beaumont    ENG                         765   \n",
       "1         Lizelle Lee                           SA    758   \n",
       "2        Alyssa Healy                          AUS    756   \n",
       "3     Stafanie Taylor                           WI    746   \n",
       "4         Meg Lanning                          AUS    723   \n",
       "5   Amy Satterthwaite                           NZ    715   \n",
       "6     Smriti Mandhana                          IND    710   \n",
       "7         Mithali Raj                          IND    709   \n",
       "8      Natalie Sciver                          ENG    685   \n",
       "9     Laura Wolvaardt                           SA    683   \n",
       "\n",
       "                     Career best  \n",
       "0  765 v New Zealand, 28/02/2021  \n",
       "1        773 v India, 14/03/2021  \n",
       "2  756 v New Zealand, 10/04/2021  \n",
       "3        765 v India, 02/03/2012  \n",
       "4  834 v New Zealand, 24/02/2016  \n",
       "5    756 v Australia, 02/03/2017  \n",
       "6      797 v England, 28/02/2019  \n",
       "7    839 v Australia, 24/12/2004  \n",
       "8        712 v India, 25/02/2019  \n",
       "9        725 v India, 07/03/2021  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "women_odi = pd.DataFrame({})\n",
    "women_odi['Name'] = player_name\n",
    "women_odi['Team'] = team_name\n",
    "women_odi['Rating'] = rating\n",
    "women_odi[\"Career best\"] = career_best\n",
    "women_odi.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iii.) Top 10 women’s ODI all-rounder along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder\"\n",
    "r = requests.get(url, 'html.parser')\n",
    "soup = BeautifulSoup(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Marizanne Kapp', ' Ellyse Perry ', ' Stafanie Taylor ', ' Natalie Sciver ', ' Deepti Sharma ', ' Jess Jonassen ', ' Ashleigh Gardner ', ' Dane van Niekerk ', ' Sophie Devine ', ' Amelia Kerr ', ' Katherine Brunt ', ' Shikha Pandey ', ' Jhulan Goswami ', ' Heather Knight ', ' Rumana Ahmed ', ' Hayley Matthews ', ' Harmanpreet Kaur ', ' Chamari Athapaththu ', ' Sune Luus ', ' Poonam Yadav ']\n"
     ]
    }
   ],
   "source": [
    "#Fetching Player_Name\n",
    "\n",
    "name1 = soup.find_all('div' , class_=\"rankings-block__banner--name-large\")\n",
    "name2 = soup.find_all('td' , class_=\"table-body__cell rankings-table__name name\")\n",
    "name = name1+name2\n",
    "player_name = []\n",
    "for i in name:\n",
    "    player_name.append(i.text.replace(\"\\n\" , \" \"))\n",
    "print(player_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['  SA                     ', 'AUS', 'WI', 'ENG', 'IND', 'AUS', 'AUS', 'SA', 'NZ', 'NZ', 'ENG', 'IND', 'IND', 'ENG', 'BAN', 'WI', 'IND', 'SL', 'SA', 'IND']\n"
     ]
    }
   ],
   "source": [
    "#For Team\n",
    "\n",
    "team1 = soup.find_all('div' , class_=\"rankings-block__banner--nationality\")\n",
    "team2 = soup.find_all('span' , class_=\"table-body__logo-text\")\n",
    "team = team1+team2\n",
    "team_name = []\n",
    "for i in team:\n",
    "    team_name.append(i.text.replace(\"\\n\" , \" \"))\n",
    "print(team_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['418', '418', '410', '349', '343', '307', '252', '243', '242', '236', '236', '204', '200', '189', '179', '176', '167', '164', '153', '151']\n"
     ]
    }
   ],
   "source": [
    "#Rating\n",
    "\n",
    "r1 = soup.find_all('div' , class_=\"rankings-block__banner--rating\")\n",
    "r2 = soup.find_all('td' , class_=\"table-body__cell rating\")\n",
    "r = r1+r2\n",
    "rating = []\n",
    "for i in r:\n",
    "    rating.append(i.text.replace(\"\\n\" , \" \"))\n",
    "print(rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['418 v India, 17/03/2021',\n",
       " '548 v West Indies, 11/09/2019',\n",
       " '559 v New Zealand, 10/10/2013',\n",
       " '349 v New Zealand, 28/02/2021',\n",
       " '397 v South Africa, 09/10/2019',\n",
       " '308 v West Indies, 11/09/2019',\n",
       " '256 v New Zealand, 04/04/2021',\n",
       " '421 v Sri Lanka, 11/02/2019',\n",
       " '305 v Australia, 05/10/2020',\n",
       " '247 v Australia, 07/04/2021',\n",
       " '270 v Sri Lanka, 16/03/2019',\n",
       " '262 v South Africa, 14/10/2019',\n",
       " '308 v Australia, 02/02/2016',\n",
       " '249 v West Indies, 13/06/2019',\n",
       " '180 v Pakistan, 04/11/2019',\n",
       " '211 v England, 06/06/2019',\n",
       " '174 v South Africa, 14/03/2021',\n",
       " '187 v South Africa, 17/02/2019',\n",
       " '217 v India, 05/02/2018',\n",
       " '174 v South Africa, 11/10/2019']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Career best Rating\n",
    "cb1 = soup.find_all('span' , class_=\"rankings-block__career-best-text\")\n",
    "cb2 = soup.find_all('td' , class_=\"table-body__cell u-text-right u-hide-phablet\")\n",
    "cb = cb1+cb2\n",
    "career_best = []\n",
    "for i in cb:\n",
    "    career_best.append(i.text.strip())\n",
    "career_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Career best</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Marizanne Kapp</td>\n",
       "      <td>SA</td>\n",
       "      <td>418</td>\n",
       "      <td>418 v India, 17/03/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>418</td>\n",
       "      <td>548 v West Indies, 11/09/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stafanie Taylor</td>\n",
       "      <td>WI</td>\n",
       "      <td>410</td>\n",
       "      <td>559 v New Zealand, 10/10/2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>349</td>\n",
       "      <td>349 v New Zealand, 28/02/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Deepti Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>343</td>\n",
       "      <td>397 v South Africa, 09/10/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jess Jonassen</td>\n",
       "      <td>AUS</td>\n",
       "      <td>307</td>\n",
       "      <td>308 v West Indies, 11/09/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ashleigh Gardner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>252</td>\n",
       "      <td>256 v New Zealand, 04/04/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dane van Niekerk</td>\n",
       "      <td>SA</td>\n",
       "      <td>243</td>\n",
       "      <td>421 v Sri Lanka, 11/02/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sophie Devine</td>\n",
       "      <td>NZ</td>\n",
       "      <td>242</td>\n",
       "      <td>305 v Australia, 05/10/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Amelia Kerr</td>\n",
       "      <td>NZ</td>\n",
       "      <td>236</td>\n",
       "      <td>247 v Australia, 07/04/2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Name                       Team Rating  \\\n",
       "0      Marizanne Kapp    SA                         418   \n",
       "1       Ellyse Perry                         AUS    418   \n",
       "2    Stafanie Taylor                          WI    410   \n",
       "3     Natalie Sciver                         ENG    349   \n",
       "4      Deepti Sharma                         IND    343   \n",
       "5      Jess Jonassen                         AUS    307   \n",
       "6   Ashleigh Gardner                         AUS    252   \n",
       "7   Dane van Niekerk                          SA    243   \n",
       "8      Sophie Devine                          NZ    242   \n",
       "9        Amelia Kerr                          NZ    236   \n",
       "\n",
       "                      Career best  \n",
       "0         418 v India, 17/03/2021  \n",
       "1   548 v West Indies, 11/09/2019  \n",
       "2   559 v New Zealand, 10/10/2013  \n",
       "3   349 v New Zealand, 28/02/2021  \n",
       "4  397 v South Africa, 09/10/2019  \n",
       "5   308 v West Indies, 11/09/2019  \n",
       "6   256 v New Zealand, 04/04/2021  \n",
       "7     421 v Sri Lanka, 11/02/2019  \n",
       "8     305 v Australia, 05/10/2020  \n",
       "9     247 v Australia, 07/04/2021  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "women_odi_ar = pd.DataFrame({})\n",
    "women_odi_ar['Name'] = player_name\n",
    "women_odi_ar['Team'] = team_name\n",
    "women_odi_ar['Rating'] = rating\n",
    "women_odi_ar[\"Career best\"] = career_best\n",
    "women_odi_ar.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.)   Write a python program to scrape details of all the mobile phones under Rs. 20,000 listed on Amazon.in. The scraped data should include Product Name, Price, Image URL and Average Rating.\n",
    "\n",
    "# note : THIS QUESTION IS SKIPPED BY OUR 'SME'  (as to scrape amazon.in it use selenium which is not covered yet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.) Write a python program to extract information about the local weather from the National Weather Service website of USA, https://www.weather.gov/ for the city, San Francisco. You need to extract data about 7 day extended forecast display for the city. The data should include period, short description, temperature and description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = \"https://forecast.weather.gov/MapClick.php?lat=37.777120000000025&lon=-122.41963999999996#.YNRvkegzZEY\"\n",
    "response = requests.get(page)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This Afternoon',\n",
       " 'Tonight',\n",
       " 'Friday',\n",
       " 'Friday Night',\n",
       " 'Saturday',\n",
       " 'Saturday Night',\n",
       " 'Sunday',\n",
       " 'Sunday Night',\n",
       " 'Monday',\n",
       " 'Monday Night',\n",
       " 'Tuesday',\n",
       " 'Tuesday Night',\n",
       " 'Wednesday']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Period\n",
    "\n",
    "p = soup.find_all('div' , class_=\"col-sm-2 forecast-label\")\n",
    "\n",
    "period = []\n",
    "\n",
    "for i in p:\n",
    "    period.append(i.text.replace(\"\\n\",\"\"))\n",
    "period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sunny, with a high near 68. West wind 17 to 21 mph, with gusts as high as 28 mph.',\n",
       " 'Increasing clouds, with a low around 55. Breezy, with a west wind 14 to 22 mph, with gusts as high as 29 mph.',\n",
       " 'Mostly cloudy, then gradually becoming sunny, with a high near 68. Breezy, with a west wind 13 to 23 mph, with gusts as high as 30 mph.',\n",
       " 'Increasing clouds, with a low around 56. Breezy, with a west wind 20 to 25 mph decreasing to 13 to 18 mph after midnight. Winds could gust as high as 32 mph.',\n",
       " 'Mostly sunny, with a high near 71. Breezy, with a west wind 10 to 15 mph increasing to 18 to 23 mph in the afternoon. Winds could gust as high as 31 mph.',\n",
       " 'Partly cloudy, with a low around 56. Breezy.',\n",
       " 'Mostly sunny, with a high near 69.',\n",
       " 'Mostly cloudy, with a low around 57.',\n",
       " 'Mostly sunny, with a high near 70.',\n",
       " 'Partly cloudy, with a low around 57.',\n",
       " 'Sunny, with a high near 73.',\n",
       " 'Partly cloudy, with a low around 58.',\n",
       " 'Mostly sunny, with a high near 72.']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Description\n",
    "\n",
    "d = soup.find_all('div' , class_=\"col-sm-10 forecast-text\")\n",
    "description = []\n",
    "\n",
    "for i in d:\n",
    "    description.append(i.text.strip())\n",
    "description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time Period/Day</th>\n",
       "      <th>Description and Temp.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This Afternoon</td>\n",
       "      <td>Sunny, with a high near 68. West wind 17 to 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tonight</td>\n",
       "      <td>Increasing clouds, with a low around 55. Breez...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Friday</td>\n",
       "      <td>Mostly cloudy, then gradually becoming sunny, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Friday Night</td>\n",
       "      <td>Increasing clouds, with a low around 56. Breez...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Saturday</td>\n",
       "      <td>Mostly sunny, with a high near 71. Breezy, wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Saturday Night</td>\n",
       "      <td>Partly cloudy, with a low around 56. Breezy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sunday</td>\n",
       "      <td>Mostly sunny, with a high near 69.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sunday Night</td>\n",
       "      <td>Mostly cloudy, with a low around 57.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Monday</td>\n",
       "      <td>Mostly sunny, with a high near 70.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Monday Night</td>\n",
       "      <td>Partly cloudy, with a low around 57.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Sunny, with a high near 73.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Tuesday Night</td>\n",
       "      <td>Partly cloudy, with a low around 58.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Mostly sunny, with a high near 72.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time Period/Day                              Description and Temp.\n",
       "0   This Afternoon  Sunny, with a high near 68. West wind 17 to 21...\n",
       "1          Tonight  Increasing clouds, with a low around 55. Breez...\n",
       "2           Friday  Mostly cloudy, then gradually becoming sunny, ...\n",
       "3     Friday Night  Increasing clouds, with a low around 56. Breez...\n",
       "4         Saturday  Mostly sunny, with a high near 71. Breezy, wit...\n",
       "5   Saturday Night       Partly cloudy, with a low around 56. Breezy.\n",
       "6           Sunday                 Mostly sunny, with a high near 69.\n",
       "7     Sunday Night               Mostly cloudy, with a low around 57.\n",
       "8           Monday                 Mostly sunny, with a high near 70.\n",
       "9     Monday Night               Partly cloudy, with a low around 57.\n",
       "10         Tuesday                        Sunny, with a high near 73.\n",
       "11   Tuesday Night               Partly cloudy, with a low around 58.\n",
       "12       Wednesday                 Mostly sunny, with a high near 72."
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "san_francisco = pd.DataFrame({})\n",
    "san_francisco['Time Period/Day'] = period\n",
    "san_francisco['Description and Temp.'] = description\n",
    "san_francisco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.) .Write a python program to scrape fresher job listings from ‘https://internshala.com/’. It should include job title, company name, CTC, and apply date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://internshala.com/fresher-jobs\"\n",
    "r = requests.get(url)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(r.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Software Developer ',\n",
       " 'Management Trainee - Assistant Category Manager ',\n",
       " 'Account Executive - Field Sales ',\n",
       " 'Software Engineer ',\n",
       " 'Associate Software Developer ',\n",
       " 'Social Media Strategist And Copywriter ',\n",
       " 'Level 1 Technical Support Engineer ',\n",
       " 'Associate Software Developer ',\n",
       " 'Accounting Assistant ',\n",
       " 'Software Engineer ',\n",
       " 'Business Development Manager ',\n",
       " 'Business Development Executive ',\n",
       " 'Product Developer - Mathematics ',\n",
       " 'Sales Development Representative ',\n",
       " 'Full Stack Engineer ',\n",
       " 'Junior ReactJS Developer ',\n",
       " 'Marketing Manager ',\n",
       " 'Product Marketing Associate ',\n",
       " 'Administration Associate ',\n",
       " 'Recruiter ',\n",
       " 'Associate Software Developer ',\n",
       " 'Project Coordinator ',\n",
       " 'Web Developer ',\n",
       " 'Software Engineer Trainee ',\n",
       " 'Business Development Specialist (Sales & Marketing) ',\n",
       " 'Business Development Executive ',\n",
       " 'Associate Front End Developer ',\n",
       " 'Corporate Sales Executive ',\n",
       " 'Associate Software Developer (Full-Stack - React And Node) ',\n",
       " 'Customer Relationship Specialist ',\n",
       " 'Associate Editor Engagement ',\n",
       " 'Management Consultant Associate ',\n",
       " 'Web Analytics Developer ',\n",
       " 'Junior Social Media Marketing Manager ',\n",
       " 'Junior Social Media Marketing Associate ',\n",
       " 'Business Development Manager (Digital Marketing Sales) ',\n",
       " 'Business Development Executive ',\n",
       " 'Accountant ',\n",
       " 'Research Associate ',\n",
       " 'Assistant Coordinator - Tender Department ']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting job title , company name , CTC , apply Date\n",
    "\n",
    "title = soup.find_all('div' , class_=\"heading_4_5 profile\")\n",
    "job_title = []\n",
    "\n",
    "for i in title:\n",
    "    job_title.append(i.text.replace(\"\\n\" , \"\"))\n",
    "job_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Aptigenz Solutions Private Limited',\n",
       " 'Noise',\n",
       " 'RoaDo',\n",
       " 'CrewKarma',\n",
       " 'IQGateway',\n",
       " 'Internshala',\n",
       " 'Mithi Software Technologies Private Limited',\n",
       " 'White Blink',\n",
       " 'Wono Inc',\n",
       " 'Wono Inc',\n",
       " 'Wono Inc',\n",
       " 'Emertxe Information Technologies',\n",
       " 'Open Door Education',\n",
       " 'Content Beta',\n",
       " 'Softway Solutions Private Limited',\n",
       " 'DeepThought Edutech Ventures Private Limited',\n",
       " 'Saltoro Coffee Roasters',\n",
       " 'WebMOBI',\n",
       " 'Global Sun',\n",
       " 'Radish Consultants Private Limited',\n",
       " 'Medico Healthcare Services & Technologies',\n",
       " 'Edupixels',\n",
       " 'Manufac Analytics Private Limited',\n",
       " 'Swabhav Techlabs',\n",
       " 'Claraeon Learning Private Limited',\n",
       " 'Picostone',\n",
       " 'AIMonk Labs Technology Limited',\n",
       " '369 Zoss Waters',\n",
       " 'SleekSky LLC',\n",
       " 'InPhase Power Technologies',\n",
       " 'Cactus Communications Private Limited',\n",
       " 'StrategyCo.Global',\n",
       " 'DataVinci Private Limited',\n",
       " 'The Test Tribe',\n",
       " 'Glu Studios',\n",
       " 'Graygraph Technologies LLC',\n",
       " 'BookLeaf Publishing',\n",
       " 'Ravi Ladia & Co',\n",
       " 'Market Vistas Consumer Insights',\n",
       " 'Global Source Trading LLC']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_name = soup.find_all('div' , class_=\"heading_6 company_name\")\n",
    "company_title = []\n",
    "\n",
    "for i in company_name:\n",
    "    company_title.append(i.text.strip())\n",
    "company_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Starts\\xa0Immediately',\n",
       " '3 - 3.2 LPA',\n",
       " \"24 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '6 - 10 LPA',\n",
       " \"24 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3.2 - 4 LPA',\n",
       " \"24 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 - 5 LPA',\n",
       " \"24 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3.6 - 10 LPA',\n",
       " \"24 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '5 - 6.8 LPA',\n",
       " \"24 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 LPA',\n",
       " \"23 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 - 3.6 LPA',\n",
       " \"23 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '5.4 - 6.1 LPA',\n",
       " \"23 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '5.5 - 6.3 LPA',\n",
       " \"23 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '5.2 - 5.8 LPA',\n",
       " \"23 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 LPA',\n",
       " \"23 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '7 - 8 LPA',\n",
       " \"22 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 - 4 LPA',\n",
       " \"22 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '5.5 - 9 LPA',\n",
       " \"22 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 - 5 LPA',\n",
       " \"22 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3.2 - 3.5 LPA',\n",
       " \"22 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 LPA',\n",
       " \"22 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 - 3.2 LPA',\n",
       " \"21 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 - 5 LPA',\n",
       " \"21 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 - 3.2 LPA',\n",
       " \"21 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 LPA',\n",
       " \"21 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 - 4 LPA',\n",
       " \"19 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 - 3.5 LPA',\n",
       " \"19 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 LPA',\n",
       " \"23 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 - 6.5 LPA',\n",
       " \"19 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '6 - 7 LPA',\n",
       " \"18 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 - 5 LPA',\n",
       " \"18 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '4 LPA',\n",
       " \"18 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 - 3.5 LPA',\n",
       " \"18 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 - 4 LPA',\n",
       " \"18 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '4.5 - 7 LPA',\n",
       " \"18 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '4.99 - 5 LPA',\n",
       " \"17 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 - 4 LPA',\n",
       " \"17 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 - 3.6 LPA',\n",
       " \"17 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 - 4.5 LPA',\n",
       " \"17 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 - 3.6 LPA',\n",
       " \"17 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 LPA',\n",
       " \"16 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 - 3.25 LPA',\n",
       " \"17 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 LPA',\n",
       " \"16 Jul' 21\"]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctc_ = soup.find_all('div' , class_=\"item_body\")\n",
    "ctc = []\n",
    "\n",
    "for i in ctc_:\n",
    "    ctc.append(i.text.strip())\n",
    "ctc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3 - 3.2 LPA', \"24 Jul' 21\", '6 - 10 LPA', \"24 Jul' 21\", '3.2 - 4 LPA', \"24 Jul' 21\", '3 - 5 LPA', \"24 Jul' 21\", '3.6 - 10 LPA', \"24 Jul' 21\", '5 - 6.8 LPA', \"24 Jul' 21\", '3 LPA', \"23 Jul' 21\", '3 - 3.6 LPA', \"23 Jul' 21\", '5.4 - 6.1 LPA', \"23 Jul' 21\", '5.5 - 6.3 LPA', \"23 Jul' 21\", '5.2 - 5.8 LPA', \"23 Jul' 21\", '3 LPA', \"23 Jul' 21\", '7 - 8 LPA', \"22 Jul' 21\", '3 - 4 LPA', \"22 Jul' 21\", '5.5 - 9 LPA', \"22 Jul' 21\", '3 - 5 LPA', \"22 Jul' 21\", '3.2 - 3.5 LPA', \"22 Jul' 21\", '3 LPA', \"22 Jul' 21\", '3 - 3.2 LPA', \"21 Jul' 21\", '3 - 5 LPA', \"21 Jul' 21\", '3 - 3.2 LPA', \"21 Jul' 21\", '3 LPA', \"21 Jul' 21\", '3 - 4 LPA', \"19 Jul' 21\", '3 - 3.5 LPA', \"19 Jul' 21\", '3 LPA', \"23 Jul' 21\", '3 - 6.5 LPA', \"19 Jul' 21\", '6 - 7 LPA', \"18 Jul' 21\", '3 - 5 LPA', \"18 Jul' 21\", '4 LPA', \"18 Jul' 21\", '3 - 3.5 LPA', \"18 Jul' 21\", '3 - 4 LPA', \"18 Jul' 21\", '4.5 - 7 LPA', \"18 Jul' 21\", '4.99 - 5 LPA', \"17 Jul' 21\", '3 - 4 LPA', \"17 Jul' 21\", '3 - 3.6 LPA', \"17 Jul' 21\", '3 - 4.5 LPA', \"17 Jul' 21\", '3 - 3.6 LPA', \"17 Jul' 21\", '3 LPA', \"16 Jul' 21\", '3 - 3.25 LPA', \"17 Jul' 21\", '3 LPA', \"16 Jul' 21\"]\n"
     ]
    }
   ],
   "source": [
    "for ele in ctc:\n",
    "    if ele == 'Starts\\xa0Immediately':\n",
    "        ctc.remove(ele)\n",
    "print(ctc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    }
   ],
   "source": [
    "print(len(ctc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ctc[1:78:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3 - 3.2 LPA',\n",
       " '6 - 10 LPA',\n",
       " '3.2 - 4 LPA',\n",
       " '3 - 5 LPA',\n",
       " '3.6 - 10 LPA',\n",
       " '5 - 6.8 LPA',\n",
       " '3 LPA',\n",
       " '3 - 3.6 LPA',\n",
       " '5.4 - 6.1 LPA',\n",
       " '5.5 - 6.3 LPA',\n",
       " '5.2 - 5.8 LPA',\n",
       " '3 LPA',\n",
       " '7 - 8 LPA',\n",
       " '3 - 4 LPA',\n",
       " '5.5 - 9 LPA',\n",
       " '3 - 5 LPA',\n",
       " '3.2 - 3.5 LPA',\n",
       " '3 LPA',\n",
       " '3 - 3.2 LPA',\n",
       " '3 - 5 LPA',\n",
       " '3 - 3.2 LPA',\n",
       " '3 LPA',\n",
       " '3 - 4 LPA',\n",
       " '3 - 3.5 LPA',\n",
       " '3 LPA',\n",
       " '3 - 6.5 LPA',\n",
       " '6 - 7 LPA',\n",
       " '3 - 5 LPA',\n",
       " '4 LPA',\n",
       " '3 - 3.5 LPA',\n",
       " '3 - 4 LPA',\n",
       " '4.5 - 7 LPA',\n",
       " '4.99 - 5 LPA',\n",
       " '3 - 4 LPA',\n",
       " '3 - 3.6 LPA',\n",
       " '3 - 4.5 LPA',\n",
       " '3 - 3.6 LPA',\n",
       " '3 LPA',\n",
       " '3 - 3.25 LPA',\n",
       " '3 LPA']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del ctc[-1]\n",
    "ctc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Starts\\xa0Immediately',\n",
       " '3 - 3.2 LPA',\n",
       " \"24 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '6 - 10 LPA',\n",
       " \"24 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3.2 - 4 LPA',\n",
       " \"24 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 - 5 LPA',\n",
       " \"24 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3.6 - 10 LPA',\n",
       " \"24 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '5 - 6.8 LPA',\n",
       " \"24 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 LPA',\n",
       " \"23 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 - 3.6 LPA',\n",
       " \"23 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '5.4 - 6.1 LPA',\n",
       " \"23 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '5.5 - 6.3 LPA',\n",
       " \"23 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '5.2 - 5.8 LPA',\n",
       " \"23 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 LPA',\n",
       " \"23 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '7 - 8 LPA',\n",
       " \"22 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 - 4 LPA',\n",
       " \"22 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '5.5 - 9 LPA',\n",
       " \"22 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 - 5 LPA',\n",
       " \"22 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3.2 - 3.5 LPA',\n",
       " \"22 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 LPA',\n",
       " \"22 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 - 3.2 LPA',\n",
       " \"21 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 - 5 LPA',\n",
       " \"21 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 - 3.2 LPA',\n",
       " \"21 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 LPA',\n",
       " \"21 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 - 4 LPA',\n",
       " \"19 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 - 3.5 LPA',\n",
       " \"19 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 LPA',\n",
       " \"23 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 - 6.5 LPA',\n",
       " \"19 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '6 - 7 LPA',\n",
       " \"18 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 - 5 LPA',\n",
       " \"18 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '4 LPA',\n",
       " \"18 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 - 3.5 LPA',\n",
       " \"18 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 - 4 LPA',\n",
       " \"18 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '4.5 - 7 LPA',\n",
       " \"18 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '4.99 - 5 LPA',\n",
       " \"17 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 - 4 LPA',\n",
       " \"17 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 - 3.6 LPA',\n",
       " \"17 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 - 4.5 LPA',\n",
       " \"17 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 - 3.6 LPA',\n",
       " \"17 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 LPA',\n",
       " \"16 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 - 3.25 LPA',\n",
       " \"17 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 LPA',\n",
       " \"16 Jul' 21\"]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Similarly for Apply Date\n",
    "\n",
    "ad = soup.find_all('div' , class_=\"item_body\")\n",
    "apply_date = []\n",
    "\n",
    "for i in ad:\n",
    "    apply_date.append(i.text.strip())\n",
    "apply_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ele in apply_date:\n",
    "    if ele == 'Starts\\xa0Immediately':\n",
    "        apply_date.remove(ele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"24 Jul' 21\",\n",
       " \"24 Jul' 21\",\n",
       " \"24 Jul' 21\",\n",
       " \"24 Jul' 21\",\n",
       " \"24 Jul' 21\",\n",
       " \"24 Jul' 21\",\n",
       " \"23 Jul' 21\",\n",
       " \"23 Jul' 21\",\n",
       " \"23 Jul' 21\",\n",
       " \"23 Jul' 21\",\n",
       " \"23 Jul' 21\",\n",
       " \"23 Jul' 21\",\n",
       " \"22 Jul' 21\",\n",
       " \"22 Jul' 21\",\n",
       " \"22 Jul' 21\",\n",
       " \"22 Jul' 21\",\n",
       " \"22 Jul' 21\",\n",
       " \"22 Jul' 21\",\n",
       " \"21 Jul' 21\",\n",
       " \"21 Jul' 21\",\n",
       " \"21 Jul' 21\",\n",
       " \"21 Jul' 21\",\n",
       " \"19 Jul' 21\",\n",
       " \"19 Jul' 21\",\n",
       " \"23 Jul' 21\",\n",
       " \"19 Jul' 21\",\n",
       " \"18 Jul' 21\",\n",
       " \"18 Jul' 21\",\n",
       " \"18 Jul' 21\",\n",
       " \"18 Jul' 21\",\n",
       " \"18 Jul' 21\",\n",
       " \"18 Jul' 21\",\n",
       " \"17 Jul' 21\",\n",
       " \"17 Jul' 21\",\n",
       " \"17 Jul' 21\",\n",
       " \"17 Jul' 21\",\n",
       " \"17 Jul' 21\",\n",
       " \"16 Jul' 21\",\n",
       " \"17 Jul' 21\",\n",
       " \"16 Jul' 21\"]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del apply_date[0:80:2]\n",
    "apply_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "40\n",
      "40\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title))\n",
    "print(len(company_title))\n",
    "print(len(ctc))\n",
    "print(len(apply_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>CTC</th>\n",
       "      <th>Apply Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Software Developer</td>\n",
       "      <td>Aptigenz Solutions Private Limited</td>\n",
       "      <td>3 - 3.2 LPA</td>\n",
       "      <td>24 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Management Trainee - Assistant Category Manager</td>\n",
       "      <td>Noise</td>\n",
       "      <td>6 - 10 LPA</td>\n",
       "      <td>24 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Account Executive - Field Sales</td>\n",
       "      <td>RoaDo</td>\n",
       "      <td>3.2 - 4 LPA</td>\n",
       "      <td>24 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>CrewKarma</td>\n",
       "      <td>3 - 5 LPA</td>\n",
       "      <td>24 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Associate Software Developer</td>\n",
       "      <td>IQGateway</td>\n",
       "      <td>3.6 - 10 LPA</td>\n",
       "      <td>24 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Social Media Strategist And Copywriter</td>\n",
       "      <td>Internshala</td>\n",
       "      <td>5 - 6.8 LPA</td>\n",
       "      <td>24 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Level 1 Technical Support Engineer</td>\n",
       "      <td>Mithi Software Technologies Private Limited</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>23 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Associate Software Developer</td>\n",
       "      <td>White Blink</td>\n",
       "      <td>3 - 3.6 LPA</td>\n",
       "      <td>23 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Accounting Assistant</td>\n",
       "      <td>Wono Inc</td>\n",
       "      <td>5.4 - 6.1 LPA</td>\n",
       "      <td>23 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>Wono Inc</td>\n",
       "      <td>5.5 - 6.3 LPA</td>\n",
       "      <td>23 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Business Development Manager</td>\n",
       "      <td>Wono Inc</td>\n",
       "      <td>5.2 - 5.8 LPA</td>\n",
       "      <td>23 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Business Development Executive</td>\n",
       "      <td>Emertxe Information Technologies</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>23 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Product Developer - Mathematics</td>\n",
       "      <td>Open Door Education</td>\n",
       "      <td>7 - 8 LPA</td>\n",
       "      <td>22 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Sales Development Representative</td>\n",
       "      <td>Content Beta</td>\n",
       "      <td>3 - 4 LPA</td>\n",
       "      <td>22 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Full Stack Engineer</td>\n",
       "      <td>Softway Solutions Private Limited</td>\n",
       "      <td>5.5 - 9 LPA</td>\n",
       "      <td>22 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Junior ReactJS Developer</td>\n",
       "      <td>DeepThought Edutech Ventures Private Limited</td>\n",
       "      <td>3 - 5 LPA</td>\n",
       "      <td>22 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Marketing Manager</td>\n",
       "      <td>Saltoro Coffee Roasters</td>\n",
       "      <td>3.2 - 3.5 LPA</td>\n",
       "      <td>22 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Product Marketing Associate</td>\n",
       "      <td>WebMOBI</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>22 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Administration Associate</td>\n",
       "      <td>Global Sun</td>\n",
       "      <td>3 - 3.2 LPA</td>\n",
       "      <td>21 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Recruiter</td>\n",
       "      <td>Radish Consultants Private Limited</td>\n",
       "      <td>3 - 5 LPA</td>\n",
       "      <td>21 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Associate Software Developer</td>\n",
       "      <td>Medico Healthcare Services &amp; Technologies</td>\n",
       "      <td>3 - 3.2 LPA</td>\n",
       "      <td>21 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Project Coordinator</td>\n",
       "      <td>Edupixels</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>21 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Web Developer</td>\n",
       "      <td>Manufac Analytics Private Limited</td>\n",
       "      <td>3 - 4 LPA</td>\n",
       "      <td>19 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Software Engineer Trainee</td>\n",
       "      <td>Swabhav Techlabs</td>\n",
       "      <td>3 - 3.5 LPA</td>\n",
       "      <td>19 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Business Development Specialist (Sales &amp; Marke...</td>\n",
       "      <td>Claraeon Learning Private Limited</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>23 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Business Development Executive</td>\n",
       "      <td>Picostone</td>\n",
       "      <td>3 - 6.5 LPA</td>\n",
       "      <td>19 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Associate Front End Developer</td>\n",
       "      <td>AIMonk Labs Technology Limited</td>\n",
       "      <td>6 - 7 LPA</td>\n",
       "      <td>18 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Corporate Sales Executive</td>\n",
       "      <td>369 Zoss Waters</td>\n",
       "      <td>3 - 5 LPA</td>\n",
       "      <td>18 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Associate Software Developer (Full-Stack - Rea...</td>\n",
       "      <td>SleekSky LLC</td>\n",
       "      <td>4 LPA</td>\n",
       "      <td>18 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Customer Relationship Specialist</td>\n",
       "      <td>InPhase Power Technologies</td>\n",
       "      <td>3 - 3.5 LPA</td>\n",
       "      <td>18 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Associate Editor Engagement</td>\n",
       "      <td>Cactus Communications Private Limited</td>\n",
       "      <td>3 - 4 LPA</td>\n",
       "      <td>18 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Management Consultant Associate</td>\n",
       "      <td>StrategyCo.Global</td>\n",
       "      <td>4.5 - 7 LPA</td>\n",
       "      <td>18 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Web Analytics Developer</td>\n",
       "      <td>DataVinci Private Limited</td>\n",
       "      <td>4.99 - 5 LPA</td>\n",
       "      <td>17 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Junior Social Media Marketing Manager</td>\n",
       "      <td>The Test Tribe</td>\n",
       "      <td>3 - 4 LPA</td>\n",
       "      <td>17 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Junior Social Media Marketing Associate</td>\n",
       "      <td>Glu Studios</td>\n",
       "      <td>3 - 3.6 LPA</td>\n",
       "      <td>17 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Business Development Manager (Digital Marketin...</td>\n",
       "      <td>Graygraph Technologies LLC</td>\n",
       "      <td>3 - 4.5 LPA</td>\n",
       "      <td>17 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Business Development Executive</td>\n",
       "      <td>BookLeaf Publishing</td>\n",
       "      <td>3 - 3.6 LPA</td>\n",
       "      <td>17 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Accountant</td>\n",
       "      <td>Ravi Ladia &amp; Co</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>16 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Research Associate</td>\n",
       "      <td>Market Vistas Consumer Insights</td>\n",
       "      <td>3 - 3.25 LPA</td>\n",
       "      <td>17 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Assistant Coordinator - Tender Department</td>\n",
       "      <td>Global Source Trading LLC</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>16 Jul' 21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Job_Title  \\\n",
       "0                                 Software Developer    \n",
       "1    Management Trainee - Assistant Category Manager    \n",
       "2                    Account Executive - Field Sales    \n",
       "3                                  Software Engineer    \n",
       "4                       Associate Software Developer    \n",
       "5             Social Media Strategist And Copywriter    \n",
       "6                 Level 1 Technical Support Engineer    \n",
       "7                       Associate Software Developer    \n",
       "8                               Accounting Assistant    \n",
       "9                                  Software Engineer    \n",
       "10                      Business Development Manager    \n",
       "11                    Business Development Executive    \n",
       "12                   Product Developer - Mathematics    \n",
       "13                  Sales Development Representative    \n",
       "14                               Full Stack Engineer    \n",
       "15                          Junior ReactJS Developer    \n",
       "16                                 Marketing Manager    \n",
       "17                       Product Marketing Associate    \n",
       "18                          Administration Associate    \n",
       "19                                         Recruiter    \n",
       "20                      Associate Software Developer    \n",
       "21                               Project Coordinator    \n",
       "22                                     Web Developer    \n",
       "23                         Software Engineer Trainee    \n",
       "24  Business Development Specialist (Sales & Marke...   \n",
       "25                    Business Development Executive    \n",
       "26                     Associate Front End Developer    \n",
       "27                         Corporate Sales Executive    \n",
       "28  Associate Software Developer (Full-Stack - Rea...   \n",
       "29                  Customer Relationship Specialist    \n",
       "30                       Associate Editor Engagement    \n",
       "31                   Management Consultant Associate    \n",
       "32                           Web Analytics Developer    \n",
       "33             Junior Social Media Marketing Manager    \n",
       "34           Junior Social Media Marketing Associate    \n",
       "35  Business Development Manager (Digital Marketin...   \n",
       "36                    Business Development Executive    \n",
       "37                                        Accountant    \n",
       "38                                Research Associate    \n",
       "39         Assistant Coordinator - Tender Department    \n",
       "\n",
       "                                         Company            CTC  Apply Date  \n",
       "0             Aptigenz Solutions Private Limited    3 - 3.2 LPA  24 Jul' 21  \n",
       "1                                          Noise     6 - 10 LPA  24 Jul' 21  \n",
       "2                                          RoaDo    3.2 - 4 LPA  24 Jul' 21  \n",
       "3                                      CrewKarma      3 - 5 LPA  24 Jul' 21  \n",
       "4                                      IQGateway   3.6 - 10 LPA  24 Jul' 21  \n",
       "5                                    Internshala    5 - 6.8 LPA  24 Jul' 21  \n",
       "6    Mithi Software Technologies Private Limited          3 LPA  23 Jul' 21  \n",
       "7                                    White Blink    3 - 3.6 LPA  23 Jul' 21  \n",
       "8                                       Wono Inc  5.4 - 6.1 LPA  23 Jul' 21  \n",
       "9                                       Wono Inc  5.5 - 6.3 LPA  23 Jul' 21  \n",
       "10                                      Wono Inc  5.2 - 5.8 LPA  23 Jul' 21  \n",
       "11              Emertxe Information Technologies          3 LPA  23 Jul' 21  \n",
       "12                           Open Door Education      7 - 8 LPA  22 Jul' 21  \n",
       "13                                  Content Beta      3 - 4 LPA  22 Jul' 21  \n",
       "14             Softway Solutions Private Limited    5.5 - 9 LPA  22 Jul' 21  \n",
       "15  DeepThought Edutech Ventures Private Limited      3 - 5 LPA  22 Jul' 21  \n",
       "16                       Saltoro Coffee Roasters  3.2 - 3.5 LPA  22 Jul' 21  \n",
       "17                                       WebMOBI          3 LPA  22 Jul' 21  \n",
       "18                                    Global Sun    3 - 3.2 LPA  21 Jul' 21  \n",
       "19            Radish Consultants Private Limited      3 - 5 LPA  21 Jul' 21  \n",
       "20     Medico Healthcare Services & Technologies    3 - 3.2 LPA  21 Jul' 21  \n",
       "21                                     Edupixels          3 LPA  21 Jul' 21  \n",
       "22             Manufac Analytics Private Limited      3 - 4 LPA  19 Jul' 21  \n",
       "23                              Swabhav Techlabs    3 - 3.5 LPA  19 Jul' 21  \n",
       "24             Claraeon Learning Private Limited          3 LPA  23 Jul' 21  \n",
       "25                                     Picostone    3 - 6.5 LPA  19 Jul' 21  \n",
       "26                AIMonk Labs Technology Limited      6 - 7 LPA  18 Jul' 21  \n",
       "27                               369 Zoss Waters      3 - 5 LPA  18 Jul' 21  \n",
       "28                                  SleekSky LLC          4 LPA  18 Jul' 21  \n",
       "29                    InPhase Power Technologies    3 - 3.5 LPA  18 Jul' 21  \n",
       "30         Cactus Communications Private Limited      3 - 4 LPA  18 Jul' 21  \n",
       "31                             StrategyCo.Global    4.5 - 7 LPA  18 Jul' 21  \n",
       "32                     DataVinci Private Limited   4.99 - 5 LPA  17 Jul' 21  \n",
       "33                                The Test Tribe      3 - 4 LPA  17 Jul' 21  \n",
       "34                                   Glu Studios    3 - 3.6 LPA  17 Jul' 21  \n",
       "35                    Graygraph Technologies LLC    3 - 4.5 LPA  17 Jul' 21  \n",
       "36                           BookLeaf Publishing    3 - 3.6 LPA  17 Jul' 21  \n",
       "37                               Ravi Ladia & Co          3 LPA  16 Jul' 21  \n",
       "38               Market Vistas Consumer Insights   3 - 3.25 LPA  17 Jul' 21  \n",
       "39                     Global Source Trading LLC          3 LPA  16 Jul' 21  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "internshala = pd.DataFrame({})\n",
    "internshala['Job_Title'] = job_title\n",
    "internshala['Company'] = company_title\n",
    "internshala['CTC'] = ctc\n",
    "internshala['Apply Date'] = apply_date\n",
    "internshala\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10.) Write a python program to scrape house details from mentioned url. It should include house title, location, area, emi and price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://www.nobroker.in/property/sale/bangalore/Electronic%20City?searchParam=W3sibGF0IjoxMi44NDUyMTQ1LCJsb24iOjc3LjY2MDE2OTUsInBsYWNlSWQiOiJDaElKdy1GUWQ0cHNyanNSSGZkYXpnXzhYRW8iLCJwbGFjZU5hbWUiOiJFbGVjdHJvbmljIENpdHkifV0=&radius=2.0\"\n",
    "response = requests.get(url)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3 BHK Apartment  For Sale  In Smondoville, Electronic City In Electronic City',\n",
       " '2 BHK Apartment  For Sale  In Ds Sigma Nest In Electronic City',\n",
       " '2 BHK Apartment  For Sale  In Gm Infinite E-city Town In Electronic City',\n",
       " '1 BHK Apartment  For Sale  In Shriram Summitt In Electronic City',\n",
       " '3 BHK Apartment  For Sale  In Ds-max Starry In Electronic City',\n",
       " '3 BHK Flat  For Sale  In Greenfinch Vallerian In Electronic City',\n",
       " '2 BHK Apartment  For Sale  In Purnima Elite In Electronic City',\n",
       " '2 BHK Apartment  For Sale  In Sriven Luminous Amaltas In Electronic City',\n",
       " '2 BHK Apartment  For Sale  In Icon Happy Living In Electronic City',\n",
       " '3 BHK Apartment  For Sale  In Mahendra Aarna In Ananth Nagar Phase 2']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = soup.find_all('h2' , class_=\"heading-6 font-semi-bold nb__1AShY\")\n",
    "\n",
    "house_title = []\n",
    "for i in title:\n",
    "    house_title.append(i.text.strip())\n",
    "house_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1,350 sqft',\n",
       " '1,240 sqft',\n",
       " '1,070 sqft',\n",
       " '770 sqft',\n",
       " '1,088 sqft',\n",
       " '1,527 sqft',\n",
       " '995 sqft',\n",
       " '940 sqft',\n",
       " '765 sqft',\n",
       " '1,380 sqft']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Similarly doing for area , emi & price\n",
    "\n",
    "area_ = soup.find_all('div' , class_=\"nb__3oNyC\")\n",
    "area = []\n",
    "\n",
    "for i in area_:\n",
    "    area.append(i.text.strip())\n",
    "area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹29,803/Month',\n",
       " '₹31,522/Month',\n",
       " '₹33,242/Month',\n",
       " '₹25,791/Month',\n",
       " '₹22,925/Month',\n",
       " '₹63,045/Month',\n",
       " '₹23,498/Month',\n",
       " '₹24,072/Month',\n",
       " '₹24,645/Month',\n",
       " '₹47,571/Month']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emi_ = soup.find_all('div' , class_=\"font-semi-bold heading-6\" , id=\"roomType\")\n",
    "emi=[]\n",
    "\n",
    "for i in emi_:\n",
    "    emi.append(i.text.strip())\n",
    "emi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹52 Lacs₹3,852 per sq.ft.',\n",
       " '₹55 Lacs₹4,435 per sq.ft.',\n",
       " '₹58 Lacs₹5,421 per sq.ft.',\n",
       " '₹45 Lacs₹5,844 per sq.ft.',\n",
       " '₹40 Lacs₹3,676 per sq.ft.',\n",
       " '₹1.1 Crores₹7,204 per sq.ft.',\n",
       " '₹41 Lacs₹4,121 per sq.ft.',\n",
       " '₹42 Lacs₹4,468 per sq.ft.',\n",
       " '₹43 Lacs₹5,621 per sq.ft.',\n",
       " '₹83 Lacs₹6,014 per sq.ft.']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_ = soup.find_all('div' , class_=\"nb__2NPHR\" , itemprop=\"valueReference\" , id=\"minDeposit\")\n",
    "price =[]\n",
    "\n",
    "for i in price_:\n",
    "    price.append(i.text.strip())\n",
    "price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Area</th>\n",
       "      <th>Emi</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3 BHK Apartment  For Sale  In Smondoville, Ele...</td>\n",
       "      <td>1,350 sqft</td>\n",
       "      <td>₹29,803/Month</td>\n",
       "      <td>₹52 Lacs₹3,852 per sq.ft.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2 BHK Apartment  For Sale  In Ds Sigma Nest In...</td>\n",
       "      <td>1,240 sqft</td>\n",
       "      <td>₹31,522/Month</td>\n",
       "      <td>₹55 Lacs₹4,435 per sq.ft.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2 BHK Apartment  For Sale  In Gm Infinite E-ci...</td>\n",
       "      <td>1,070 sqft</td>\n",
       "      <td>₹33,242/Month</td>\n",
       "      <td>₹58 Lacs₹5,421 per sq.ft.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1 BHK Apartment  For Sale  In Shriram Summitt ...</td>\n",
       "      <td>770 sqft</td>\n",
       "      <td>₹25,791/Month</td>\n",
       "      <td>₹45 Lacs₹5,844 per sq.ft.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3 BHK Apartment  For Sale  In Ds-max Starry In...</td>\n",
       "      <td>1,088 sqft</td>\n",
       "      <td>₹22,925/Month</td>\n",
       "      <td>₹40 Lacs₹3,676 per sq.ft.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3 BHK Flat  For Sale  In Greenfinch Vallerian ...</td>\n",
       "      <td>1,527 sqft</td>\n",
       "      <td>₹63,045/Month</td>\n",
       "      <td>₹1.1 Crores₹7,204 per sq.ft.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2 BHK Apartment  For Sale  In Purnima Elite In...</td>\n",
       "      <td>995 sqft</td>\n",
       "      <td>₹23,498/Month</td>\n",
       "      <td>₹41 Lacs₹4,121 per sq.ft.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2 BHK Apartment  For Sale  In Sriven Luminous ...</td>\n",
       "      <td>940 sqft</td>\n",
       "      <td>₹24,072/Month</td>\n",
       "      <td>₹42 Lacs₹4,468 per sq.ft.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2 BHK Apartment  For Sale  In Icon Happy Livin...</td>\n",
       "      <td>765 sqft</td>\n",
       "      <td>₹24,645/Month</td>\n",
       "      <td>₹43 Lacs₹5,621 per sq.ft.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3 BHK Apartment  For Sale  In Mahendra Aarna I...</td>\n",
       "      <td>1,380 sqft</td>\n",
       "      <td>₹47,571/Month</td>\n",
       "      <td>₹83 Lacs₹6,014 per sq.ft.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title        Area  \\\n",
       "0  3 BHK Apartment  For Sale  In Smondoville, Ele...  1,350 sqft   \n",
       "1  2 BHK Apartment  For Sale  In Ds Sigma Nest In...  1,240 sqft   \n",
       "2  2 BHK Apartment  For Sale  In Gm Infinite E-ci...  1,070 sqft   \n",
       "3  1 BHK Apartment  For Sale  In Shriram Summitt ...    770 sqft   \n",
       "4  3 BHK Apartment  For Sale  In Ds-max Starry In...  1,088 sqft   \n",
       "5  3 BHK Flat  For Sale  In Greenfinch Vallerian ...  1,527 sqft   \n",
       "6  2 BHK Apartment  For Sale  In Purnima Elite In...    995 sqft   \n",
       "7  2 BHK Apartment  For Sale  In Sriven Luminous ...    940 sqft   \n",
       "8  2 BHK Apartment  For Sale  In Icon Happy Livin...    765 sqft   \n",
       "9  3 BHK Apartment  For Sale  In Mahendra Aarna I...  1,380 sqft   \n",
       "\n",
       "             Emi                         Price  \n",
       "0  ₹29,803/Month     ₹52 Lacs₹3,852 per sq.ft.  \n",
       "1  ₹31,522/Month     ₹55 Lacs₹4,435 per sq.ft.  \n",
       "2  ₹33,242/Month     ₹58 Lacs₹5,421 per sq.ft.  \n",
       "3  ₹25,791/Month     ₹45 Lacs₹5,844 per sq.ft.  \n",
       "4  ₹22,925/Month     ₹40 Lacs₹3,676 per sq.ft.  \n",
       "5  ₹63,045/Month  ₹1.1 Crores₹7,204 per sq.ft.  \n",
       "6  ₹23,498/Month     ₹41 Lacs₹4,121 per sq.ft.  \n",
       "7  ₹24,072/Month     ₹42 Lacs₹4,468 per sq.ft.  \n",
       "8  ₹24,645/Month     ₹43 Lacs₹5,621 per sq.ft.  \n",
       "9  ₹47,571/Month     ₹83 Lacs₹6,014 per sq.ft.  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_details = pd.DataFrame({})\n",
    "house_details['Title'] = house_title\n",
    "house_details['Area'] = area\n",
    "house_details['Emi'] = emi\n",
    "house_details['Price'] = price\n",
    "house_details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# .......**********........"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
